{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e54ac9",
   "metadata": {},
   "source": [
    "# Homework Assignment 5 - Deep Learning 2: Convolutional and Recurrent Neural Networks\n",
    "### **Due:** Tuesday, June 6, 11:59pm\n",
    "### Total: 100 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5bba81",
   "metadata": {},
   "source": [
    "## Import all the libraries and tools you need below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "85bacf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir(\"C:\\Data\")\n",
    "os.getcwd()\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from numpy import log,dot,e,shape\n",
    "from numpy import log,dot,e,shape\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import LSTM, MaxPooling1D, Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import Bidirectional, MaxPooling2D \n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f9629f",
   "metadata": {},
   "source": [
    "## **1)** CNN for Image Classification (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86645e8b",
   "metadata": {},
   "source": [
    "**Before you start:** This dataset and its classification is a popular problem on Kaggle, so you can use a lot of help from there on both the network architecture and the image generators. This is fine, since the main goal of this question is to familiarize you to use big data. **There is only one restriction: You are not permitted to use any built-in network models (VGG16, ResNet etc.) or transfer learning. You have to build your own architecture from scratch and train it.** Anything else is permitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea15ff29",
   "metadata": {},
   "source": [
    "In this question, you will need a Convolutional Neural Network (CNN) to classify patients that are healthy (0) and patients with pneumonia (1) using their chest x-ray images. \n",
    "\n",
    "First of all, the image dataset for this question too big to read in your Python memory, so **you should not try to directly read it.** What you need is data generator objects that will read the data in batches without trying to hold all the images in memory.\n",
    "\n",
    "Download and put the [chest_xray](https://nuwildcat-my.sharepoint.com/:f:/r/personal/ebf987_ads_northwestern_edu/Documents/chest_xray?csf=1&web=1&e=t3293g) folder somewhere on your machine (or Drive folder for Colab) and put this .ipynb file in the same location. The cell below creates the paths that the image generators will use to pull the images and also some values to process the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18699158",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'chest_xray/train'\n",
    "test_path = 'chest_xray/test'\n",
    "val_path = 'chest_xray/val'\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "img_height = 500\n",
    "img_weight = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4ecce",
   "metadata": {},
   "source": [
    "**a)** Using the **ImageDataGenerator** class from **keras.preprocessing.image**, create two generator objects. The first one should be for training and it should include data augmentation to train the network better. Data augmentation means increasing the training data size with certain image processing tools. Very common data augmentation tools are zooming and shearing different parts of a training image and using these parts as different training images. The first generator inputs:\n",
    "\n",
    "- rescale ratio should be set to 1/255\n",
    "- shear range should be 0.2\n",
    "- zoom range should be 0.2\n",
    "\n",
    "**(4 points)**\n",
    "\n",
    "**b)** Create the second generator object with only the rescale ratio input. This one will be for the validation and test datasets and it does not need any augmentation tools.\n",
    "\n",
    "**(3 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "710fb233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "#B\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1/255\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c7164a",
   "metadata": {},
   "source": [
    "**c)** Using the generator objects and their **.flow_from_directory** method, create the generators for the training, validation and test data.\n",
    "\n",
    "- You need the training generator object for the training generator only. The validation and test generators need the test generator object.\n",
    "\n",
    "- In all generators, you need the proper **path**, the **target size** and the **batch size**. (values given above)\n",
    "\n",
    "- For all generators, set the **color mode** to **\"grayscale\"** and the **class mode** to **\"binary\"**, since these are the settings for the task.\n",
    "\n",
    "- **shuffle** should be **True** only for the training data.\n",
    "\n",
    "**(8 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68bbd2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(img_weight, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(img_weight, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(img_weight, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4adab",
   "metadata": {},
   "source": [
    "**d)** Create a CNN for the binary classification task.\n",
    "\n",
    "Compile the network using the proper cost function and an optimizer of your choice. **(3 points)** Don't forget to set the number of epochs and other necessary inputs while training. **(4 points)** After the network is trained, print the test accuracy. **(3 points)**\n",
    "\n",
    "The entire architecture and the training inputs are your choice. Your network should return a test accuracy higher than 88%. **(10 points)**\n",
    "\n",
    "A few notes:\n",
    "\n",
    "- Instead of X_train and y_train, you only need the training generator defined above, which will read both from the given directory.\n",
    "\n",
    "- Since you do not have a y_train, you cannot one-hot-encode it. This means you cannot have an output layer with two nodes. You need to work around this by changing the output layer, its function and the cost function. (Check the slides.)\n",
    "\n",
    "- Instead of validation split, use validation data and set it to the validation generator.\n",
    "\n",
    "- Note that you do not have a y_test for this question; you only have the test generator. To calculate the test accuracy, follow these steps:\n",
    "    - While compiling the network, use the **metrics** input and set it to **accuracy**.\n",
    "    - After the training is done, use **.evaluate** instead of **.predict**, with the test generator. This will return the test loss and test accuracy as two outputs, respectively.\n",
    "    \n",
    "- The training will take some time. (25 minutes on my machine to pass 88%.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af154415",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_weight, img_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbb753a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "326/326 [==============================] - 2172s 7s/step - loss: 0.5018 - accuracy: 0.8390 - val_loss: 1.1501 - val_accuracy: 0.6250\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 1346s 4s/step - loss: 0.2344 - accuracy: 0.9086 - val_loss: 0.3488 - val_accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 1787s 5s/step - loss: 0.1988 - accuracy: 0.9237 - val_loss: 0.9579 - val_accuracy: 0.6250\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 1537s 5s/step - loss: 0.1930 - accuracy: 0.9262 - val_loss: 0.5421 - val_accuracy: 0.6875\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 1538s 5s/step - loss: 0.1756 - accuracy: 0.9333 - val_loss: 0.8329 - val_accuracy: 0.6250\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 2581s 8s/step - loss: 0.1758 - accuracy: 0.9321 - val_loss: 0.9723 - val_accuracy: 0.6250\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 1256s 4s/step - loss: 0.1602 - accuracy: 0.9427 - val_loss: 0.2760 - val_accuracy: 0.8125\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 1583s 5s/step - loss: 0.1629 - accuracy: 0.9335 - val_loss: 0.3659 - val_accuracy: 0.8125\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 1912s 6s/step - loss: 0.1455 - accuracy: 0.9442 - val_loss: 0.5136 - val_accuracy: 0.6875\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 1514s 5s/step - loss: 0.1400 - accuracy: 0.9473 - val_loss: 0.3785 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f480564760>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e4d3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 31s 723ms/step - loss: 0.3891 - accuracy: 0.8958\n",
      "Test Accuracy: 0.8958333134651184\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10afd347",
   "metadata": {},
   "source": [
    "## 2) CNN for Sequence Classification (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb07605",
   "metadata": {},
   "source": [
    "In this question, you will use a CNN to classify the cardiac arrhythmia dataset you used for the previous homework assignment. Use the same lines below that preprocess the data and create the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "cc536e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    72471\n",
      "4.0     6431\n",
      "2.0     5788\n",
      "1.0     2223\n",
      "3.0      641\n",
      "Name: 187, dtype: int64\n",
      "0.0    8000\n",
      "4.0    6431\n",
      "2.0    5788\n",
      "1.0    2223\n",
      "3.0     641\n",
      "Name: 187, dtype: int64\n",
      "(20774, 187)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('heartbeat_dataset.csv', header=None)\n",
    "#data=pd.DataFrame(data)\n",
    "\n",
    "# One heartbeat\n",
    "plt.plot(data.iloc[1,:])\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('Voltage')\n",
    "plt.plot()\n",
    "\n",
    "# Overall class distribution\n",
    "print(data[187].value_counts())\n",
    "\n",
    "# Downsampling Class 0 instances to 8000\n",
    "class_other = data[data[187]!=0.0]\n",
    "class_0 = data[data[187]==0.0].sample(n = 8000, random_state=1)\n",
    "data_sampled = pd.concat([class_0, class_other])\n",
    "\n",
    "# The new class distribution.\n",
    "print(data_sampled[187].value_counts())\n",
    "\n",
    "# Separating the features and the labels into X and y variables.\n",
    "y = data_sampled[187]\n",
    "X = data_sampled.drop([187], axis=1)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=1, test_size=0.1)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c22a31",
   "metadata": {},
   "source": [
    "**a)** Note that even though the instances are not images, they have a one-dimensional temporal structure, which can be used as additional information by a CNN.  To use this data as a \"one-dimensional image\" dataset, you need to add a third dimension, which is the number of channels. For this single-sequence (the medical term is single-lead) heartbeat dataset, the number of channels is 1.\n",
    "\n",
    "Reshape both the training and the test datasets. The datasets should have their three dimensions as **(number of instances, sequence length, number of channels)**. **(5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c359805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2309, 5)\n",
      "(20774, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], X_train.shape[1], 1)\n",
    "\n",
    "y_test.shape\n",
    "y_test_reshaped = np.array(y_test).reshape((-1, 1))\n",
    "y_test_categorical = to_categorical(y_test_reshaped, num_classes=5)\n",
    "print(y_test_categorical.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cfa0ea",
   "metadata": {},
   "source": [
    "**b)** Create a CNN for the 5-class classification task.\n",
    "\n",
    "Compile the network using the proper cost function and an optimizer of your choice. **(3 points)** Don't forget to set the number of epochs and other necessary inputs while training. **(3 points)** Assign your training line to a history output. **(2 points)**\n",
    "\n",
    "After the network is trained, print the test accuracy **(2.5 points)** and the confusion matrix **(2.5 points)**, and plot both the training and validation losses against the number of epochs. **(2 points)**\n",
    "\n",
    "The entire architecture and the training inputs are your choice. Your network should return a test accuracy higher than 96%. **(10 points)**\n",
    "\n",
    "**Important Note:** Keep in mind that unlike the images we used in class, your \"images\" here are one-dimensional, which means the only dimensions you have are the **sequence length and the number of channels**. You need to set the **input shape** accordingly. Also, Conv2D and MaxPooling2D layers will not work anymore; you need their **one-dimensional counterparts**. (Explore the Keras documentation.)\n",
    "\n",
    "**You have to use convolutional layers to get credit from this question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b3bbb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', \n",
    "                 input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "#                kernel_regularizer=regularizers.l2(0.01)\n",
    "                ))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu',\n",
    "#                kernel_regularizer=regularizers.l2(0.01)\n",
    "                ))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(128, kernel_size=3, activation='relu',\n",
    "#                kernel_regularizer=regularizers.l2(0.01)\n",
    "                ))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu',\n",
    "#               kernel_regularizer=regularizers.l2(0.01)\n",
    "               ))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3af164c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 30s 103ms/step - loss: 0.6492 - accuracy: 0.7562 - val_loss: 0.3332 - val_accuracy: 0.8835\n",
      "Epoch 2/60\n",
      "293/293 [==============================] - 30s 101ms/step - loss: 0.3514 - accuracy: 0.8801 - val_loss: 0.2585 - val_accuracy: 0.9172\n",
      "Epoch 3/60\n",
      "293/293 [==============================] - 30s 103ms/step - loss: 0.2811 - accuracy: 0.9063 - val_loss: 0.2203 - val_accuracy: 0.9264\n",
      "Epoch 4/60\n",
      "293/293 [==============================] - 29s 100ms/step - loss: 0.2525 - accuracy: 0.9159 - val_loss: 0.2106 - val_accuracy: 0.9321\n",
      "Epoch 5/60\n",
      "293/293 [==============================] - 28s 97ms/step - loss: 0.2253 - accuracy: 0.9235 - val_loss: 0.1889 - val_accuracy: 0.9389\n",
      "Epoch 6/60\n",
      "293/293 [==============================] - 27s 92ms/step - loss: 0.2018 - accuracy: 0.9315 - val_loss: 0.1743 - val_accuracy: 0.9398\n",
      "Epoch 7/60\n",
      "293/293 [==============================] - 26s 89ms/step - loss: 0.1797 - accuracy: 0.9375 - val_loss: 0.1628 - val_accuracy: 0.9461\n",
      "Epoch 8/60\n",
      "293/293 [==============================] - 25s 87ms/step - loss: 0.1672 - accuracy: 0.9416 - val_loss: 0.1695 - val_accuracy: 0.9456\n",
      "Epoch 9/60\n",
      "293/293 [==============================] - 25s 87ms/step - loss: 0.1543 - accuracy: 0.9460 - val_loss: 0.1785 - val_accuracy: 0.9451\n",
      "Epoch 10/60\n",
      "293/293 [==============================] - 26s 87ms/step - loss: 0.1469 - accuracy: 0.9489 - val_loss: 0.1593 - val_accuracy: 0.9461\n",
      "Epoch 11/60\n",
      "293/293 [==============================] - 25s 87ms/step - loss: 0.1353 - accuracy: 0.9529 - val_loss: 0.1456 - val_accuracy: 0.9514\n",
      "Epoch 12/60\n",
      "293/293 [==============================] - 26s 89ms/step - loss: 0.1297 - accuracy: 0.9547 - val_loss: 0.1407 - val_accuracy: 0.9543\n",
      "Epoch 13/60\n",
      "293/293 [==============================] - 26s 88ms/step - loss: 0.1232 - accuracy: 0.9557 - val_loss: 0.1445 - val_accuracy: 0.9524\n",
      "Epoch 14/60\n",
      "293/293 [==============================] - 25s 86ms/step - loss: 0.1161 - accuracy: 0.9588 - val_loss: 0.1556 - val_accuracy: 0.9490\n",
      "Epoch 15/60\n",
      "293/293 [==============================] - 25s 87ms/step - loss: 0.1096 - accuracy: 0.9605 - val_loss: 0.1435 - val_accuracy: 0.9552\n",
      "Epoch 16/60\n",
      "293/293 [==============================] - 26s 89ms/step - loss: 0.1054 - accuracy: 0.9623 - val_loss: 0.1473 - val_accuracy: 0.9548\n",
      "Epoch 17/60\n",
      "293/293 [==============================] - 27s 91ms/step - loss: 0.0969 - accuracy: 0.9644 - val_loss: 0.1473 - val_accuracy: 0.9548\n",
      "Epoch 18/60\n",
      "293/293 [==============================] - 27s 91ms/step - loss: 0.0952 - accuracy: 0.9654 - val_loss: 0.1402 - val_accuracy: 0.9533\n",
      "Epoch 19/60\n",
      "293/293 [==============================] - 27s 92ms/step - loss: 0.0944 - accuracy: 0.9662 - val_loss: 0.1421 - val_accuracy: 0.9538\n",
      "Epoch 20/60\n",
      "293/293 [==============================] - 27s 94ms/step - loss: 0.0876 - accuracy: 0.9684 - val_loss: 0.1534 - val_accuracy: 0.9495\n",
      "Epoch 21/60\n",
      "293/293 [==============================] - 28s 96ms/step - loss: 0.0852 - accuracy: 0.9689 - val_loss: 0.1452 - val_accuracy: 0.9562\n",
      "Epoch 22/60\n",
      "293/293 [==============================] - 29s 97ms/step - loss: 0.0821 - accuracy: 0.9700 - val_loss: 0.1433 - val_accuracy: 0.9533\n",
      "Epoch 23/60\n",
      "293/293 [==============================] - 30s 104ms/step - loss: 0.0727 - accuracy: 0.9737 - val_loss: 0.1505 - val_accuracy: 0.9605\n",
      "Epoch 24/60\n",
      "293/293 [==============================] - 29s 100ms/step - loss: 0.0710 - accuracy: 0.9742 - val_loss: 0.1617 - val_accuracy: 0.9538\n",
      "Epoch 25/60\n",
      "293/293 [==============================] - 29s 100ms/step - loss: 0.0682 - accuracy: 0.9757 - val_loss: 0.1510 - val_accuracy: 0.9572\n",
      "Epoch 26/60\n",
      "293/293 [==============================] - 30s 101ms/step - loss: 0.0702 - accuracy: 0.9744 - val_loss: 0.1607 - val_accuracy: 0.9538\n",
      "Epoch 27/60\n",
      "293/293 [==============================] - 31s 106ms/step - loss: 0.0652 - accuracy: 0.9768 - val_loss: 0.1500 - val_accuracy: 0.9562\n",
      "Epoch 28/60\n",
      "293/293 [==============================] - 30s 104ms/step - loss: 0.0600 - accuracy: 0.9778 - val_loss: 0.1669 - val_accuracy: 0.9577\n",
      "Epoch 29/60\n",
      "293/293 [==============================] - 30s 103ms/step - loss: 0.0611 - accuracy: 0.9775 - val_loss: 0.1618 - val_accuracy: 0.9543\n",
      "Epoch 30/60\n",
      "293/293 [==============================] - 30s 103ms/step - loss: 0.0568 - accuracy: 0.9784 - val_loss: 0.1655 - val_accuracy: 0.9538\n",
      "Epoch 31/60\n",
      "293/293 [==============================] - 31s 105ms/step - loss: 0.0571 - accuracy: 0.9786 - val_loss: 0.1430 - val_accuracy: 0.9581\n",
      "Epoch 32/60\n",
      "293/293 [==============================] - 32s 108ms/step - loss: 0.0531 - accuracy: 0.9806 - val_loss: 0.1541 - val_accuracy: 0.9562\n",
      "Epoch 33/60\n",
      "293/293 [==============================] - 33s 112ms/step - loss: 0.0582 - accuracy: 0.9790 - val_loss: 0.1623 - val_accuracy: 0.9562\n",
      "Epoch 34/60\n",
      "293/293 [==============================] - 34s 115ms/step - loss: 0.0522 - accuracy: 0.9820 - val_loss: 0.1564 - val_accuracy: 0.9572\n",
      "Epoch 35/60\n",
      "293/293 [==============================] - 34s 116ms/step - loss: 0.0477 - accuracy: 0.9814 - val_loss: 0.1588 - val_accuracy: 0.9591\n",
      "Epoch 36/60\n",
      "293/293 [==============================] - 35s 118ms/step - loss: 0.0486 - accuracy: 0.9830 - val_loss: 0.1750 - val_accuracy: 0.9557\n",
      "Epoch 37/60\n",
      "293/293 [==============================] - 35s 119ms/step - loss: 0.0466 - accuracy: 0.9833 - val_loss: 0.1640 - val_accuracy: 0.9625\n",
      "Epoch 38/60\n",
      "293/293 [==============================] - 35s 119ms/step - loss: 0.0491 - accuracy: 0.9822 - val_loss: 0.1621 - val_accuracy: 0.9557\n",
      "Epoch 39/60\n",
      "293/293 [==============================] - 35s 119ms/step - loss: 0.0438 - accuracy: 0.9844 - val_loss: 0.1597 - val_accuracy: 0.9605\n",
      "Epoch 40/60\n",
      "293/293 [==============================] - 35s 120ms/step - loss: 0.0455 - accuracy: 0.9834 - val_loss: 0.1683 - val_accuracy: 0.9572\n",
      "Epoch 41/60\n",
      "293/293 [==============================] - 35s 119ms/step - loss: 0.0433 - accuracy: 0.9836 - val_loss: 0.1684 - val_accuracy: 0.9543\n",
      "Epoch 42/60\n",
      "293/293 [==============================] - 36s 123ms/step - loss: 0.0456 - accuracy: 0.9842 - val_loss: 0.1621 - val_accuracy: 0.9615\n",
      "Epoch 43/60\n",
      "293/293 [==============================] - 36s 122ms/step - loss: 0.0461 - accuracy: 0.9829 - val_loss: 0.1743 - val_accuracy: 0.9596\n",
      "Epoch 44/60\n",
      "293/293 [==============================] - 36s 121ms/step - loss: 0.0432 - accuracy: 0.9843 - val_loss: 0.1683 - val_accuracy: 0.9572\n",
      "Epoch 45/60\n",
      "293/293 [==============================] - 36s 122ms/step - loss: 0.0372 - accuracy: 0.9861 - val_loss: 0.1851 - val_accuracy: 0.9581\n",
      "Epoch 46/60\n",
      "293/293 [==============================] - 36s 124ms/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 0.1780 - val_accuracy: 0.9591\n",
      "Epoch 47/60\n",
      "293/293 [==============================] - 37s 125ms/step - loss: 0.0387 - accuracy: 0.9852 - val_loss: 0.1827 - val_accuracy: 0.9567\n",
      "Epoch 48/60\n",
      "293/293 [==============================] - 36s 124ms/step - loss: 0.0397 - accuracy: 0.9858 - val_loss: 0.1979 - val_accuracy: 0.9591\n",
      "Epoch 49/60\n",
      "293/293 [==============================] - 36s 122ms/step - loss: 0.0377 - accuracy: 0.9867 - val_loss: 0.1936 - val_accuracy: 0.9601\n",
      "Epoch 50/60\n",
      "293/293 [==============================] - 36s 124ms/step - loss: 0.0353 - accuracy: 0.9874 - val_loss: 0.1795 - val_accuracy: 0.9601\n",
      "Epoch 51/60\n",
      "293/293 [==============================] - 36s 123ms/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.1699 - val_accuracy: 0.9629\n",
      "Epoch 52/60\n",
      "293/293 [==============================] - 37s 125ms/step - loss: 0.0351 - accuracy: 0.9872 - val_loss: 0.1785 - val_accuracy: 0.9601\n",
      "Epoch 53/60\n",
      "293/293 [==============================] - 37s 127ms/step - loss: 0.0366 - accuracy: 0.9860 - val_loss: 0.1944 - val_accuracy: 0.9601\n",
      "Epoch 54/60\n",
      "293/293 [==============================] - 37s 125ms/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 0.1797 - val_accuracy: 0.9601\n",
      "Epoch 55/60\n",
      "293/293 [==============================] - 37s 126ms/step - loss: 0.0314 - accuracy: 0.9897 - val_loss: 0.1923 - val_accuracy: 0.9601\n",
      "Epoch 56/60\n",
      "293/293 [==============================] - 38s 130ms/step - loss: 0.0360 - accuracy: 0.9874 - val_loss: 0.1925 - val_accuracy: 0.9577\n",
      "Epoch 57/60\n",
      "293/293 [==============================] - 37s 127ms/step - loss: 0.0331 - accuracy: 0.9875 - val_loss: 0.1769 - val_accuracy: 0.9567\n",
      "Epoch 58/60\n",
      "293/293 [==============================] - 38s 130ms/step - loss: 0.0311 - accuracy: 0.9886 - val_loss: 0.1998 - val_accuracy: 0.9557\n",
      "Epoch 59/60\n",
      "293/293 [==============================] - 37s 127ms/step - loss: 0.0325 - accuracy: 0.9878 - val_loss: 0.1833 - val_accuracy: 0.9610\n",
      "Epoch 60/60\n",
      "293/293 [==============================] - 37s 128ms/step - loss: 0.0290 - accuracy: 0.9890 - val_loss: 0.1941 - val_accuracy: 0.9596\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=60, batch_size=64, \n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fa21b957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 2s 30ms/step - loss: 0.2016 - accuracy: 0.9636\n",
      "Test accuracy: 0.9636206030845642\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31316c83",
   "metadata": {},
   "source": [
    "## 3) RNN for Sequence Classification (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d5f99f",
   "metadata": {},
   "source": [
    "In this question, you will need a Recurrent Neural Network (RNN) or its modified versions (LSTM, GRU) to classify hand gestures using the electromyogram (EMG) signals taken from the hand muscles. EMG signals represent the neuromuscular activity in voltages.\n",
    "\n",
    "Run the cell below. It uploads four different files for four different gestures: rock, paper, scissors and OK. From these files, it creates the X, y values as well as the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "070b1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_dataset = pd.read_csv(\"rock.csv\", header=None) # class = 0\n",
    "scissors_dataset = pd.read_csv(\"scissors.csv\", header=None) # class = 1\n",
    "paper_dataset = pd.read_csv(\"paper.csv\", header=None) # class = 2\n",
    "ok_dataset = pd.read_csv(\"ok.csv\", header=None) # class = 3\n",
    "\n",
    "frames = [rock_dataset, scissors_dataset, paper_dataset, ok_dataset]\n",
    "dataset = pd.concat(frames)\n",
    "\n",
    "dataset_train = dataset.iloc[np.random.permutation(len(dataset))]\n",
    "dataset_train.reset_index(drop=True)\n",
    "\n",
    "y = np.array(dataset_train.iloc[:,-1])\n",
    "\n",
    "X = np.array(dataset_train.iloc[:,:-1])\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347d610",
   "metadata": {},
   "source": [
    "**a)** Note that each instance is a 64-dimensional vector. This vector represents 8 concatenated sequences that are 8 time points long each. Each sequence comes from a sensor located on a different part of the arm. Each time point represents 5 milliseconds (ms), since the data is sampled at 200 Hz, adding up to 40 ms per sequence.\n",
    "\n",
    "Before creating any network, you need to reshape the sequence and put the sequence length and the number of channels on different dimensions. The in-class assignment and the data format in the previous question should help. **(5 points)**\n",
    "\n",
    "Lastly, you need to reshape the training classes for the network. **(2 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "97f1ec30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9342, 64)\n",
      "(9342,)\n",
      "(2336,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "819e0d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9342, 4)\n",
      "(2336, 4)\n",
      "(2336, 64, 1)\n",
      "(9342, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "y_train_categorical = np.reshape(y_train_categorical, \n",
    "                                 (y_train_categorical.shape[0], y_train_categorical.shape[1]))\n",
    "y_test_categorical = np.reshape(y_test_categorical, \n",
    "                                (y_test_categorical.shape[0], y_test_categorical.shape[1]))\n",
    "\n",
    "print(y_train_categorical.shape)\n",
    "print(y_test_categorical.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0838028",
   "metadata": {},
   "source": [
    "**b)** Create a RNN for the 4-class classification task.\n",
    "\n",
    "Compile the network using the proper cost function and an optimizer of your choice. **(3 points)** Don't forget to set the number of epochs and other necessary inputs while training. **(3 points)** Assign your training line to a history output. **(2 points)**\n",
    "\n",
    "After the network is trained, print the test accuracy **(2.5 points)** and the confusion matrix **(2.5 points)**, and plot both the training and validation losses against the number of epochs. **(2 points)**\n",
    "\n",
    "The entire architecture and the training inputs are your choice. Your network should return a test accuracy higher than 97%. **(10 points)**\n",
    "\n",
    "**Note:** You can use a regular RNN, LSTM or GRU. **You have to use recurrent layers to get credit from this question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "77c53927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(LSTM(units=64), input_shape=(X_train.shape[1], 1))\n",
    "model.add(LSTM(units=256))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(learning_rate=0.001), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "76ec73ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "73/73 [==============================] - 74s 1s/step - loss: 1.1375 - accuracy: 0.4904 - val_loss: 0.8925 - val_accuracy: 0.6473\n",
      "Epoch 2/64\n",
      "73/73 [==============================] - 73s 1s/step - loss: 0.7537 - accuracy: 0.7042 - val_loss: 0.6211 - val_accuracy: 0.7705\n",
      "Epoch 3/64\n",
      "26/73 [=========>....................] - ETA: 42s - loss: 0.5776 - accuracy: 0.7776ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x000001C131162D60>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"C:\\Users\\dylan\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5160, in <genexpr>\n",
      "    ta.write(ta_index_to_write, out)  File \"C:\\Users\\dylan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "73/73 [==============================] - 76s 1s/step - loss: 0.5200 - accuracy: 0.8056 - val_loss: 0.4691 - val_accuracy: 0.8258\n",
      "Epoch 4/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.4080 - accuracy: 0.8511 - val_loss: 0.3741 - val_accuracy: 0.8647\n",
      "Epoch 5/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 0.3378 - accuracy: 0.8796 - val_loss: 0.3867 - val_accuracy: 0.8562\n",
      "Epoch 6/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.3234 - accuracy: 0.8814 - val_loss: 0.3072 - val_accuracy: 0.8836\n",
      "Epoch 7/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.2715 - accuracy: 0.9025 - val_loss: 0.2533 - val_accuracy: 0.9088\n",
      "Epoch 8/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.2420 - accuracy: 0.9155 - val_loss: 0.2751 - val_accuracy: 0.8955\n",
      "Epoch 9/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.2115 - accuracy: 0.9258 - val_loss: 0.2696 - val_accuracy: 0.9054\n",
      "Epoch 10/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.1932 - accuracy: 0.9311 - val_loss: 0.2563 - val_accuracy: 0.9067\n",
      "Epoch 11/64\n",
      "73/73 [==============================] - 78s 1s/step - loss: 0.1797 - accuracy: 0.9359 - val_loss: 0.2356 - val_accuracy: 0.9080\n",
      "Epoch 12/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.1505 - accuracy: 0.9473 - val_loss: 0.3193 - val_accuracy: 0.8806\n",
      "Epoch 13/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.1542 - accuracy: 0.9464 - val_loss: 0.2900 - val_accuracy: 0.8891\n",
      "Epoch 14/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.1602 - accuracy: 0.9444 - val_loss: 0.2161 - val_accuracy: 0.9229\n",
      "Epoch 15/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.1077 - accuracy: 0.9675 - val_loss: 0.1948 - val_accuracy: 0.9272\n",
      "Epoch 16/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0989 - accuracy: 0.9657 - val_loss: 0.1909 - val_accuracy: 0.9354\n",
      "Epoch 17/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0974 - accuracy: 0.9666 - val_loss: 0.2441 - val_accuracy: 0.9152\n",
      "Epoch 18/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0999 - accuracy: 0.9650 - val_loss: 0.1944 - val_accuracy: 0.9328\n",
      "Epoch 19/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 0.0651 - accuracy: 0.9783 - val_loss: 0.1924 - val_accuracy: 0.9319\n",
      "Epoch 20/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.2100 - val_accuracy: 0.9294\n",
      "Epoch 21/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0598 - accuracy: 0.9811 - val_loss: 0.2021 - val_accuracy: 0.9302\n",
      "Epoch 22/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0444 - accuracy: 0.9864 - val_loss: 0.1857 - val_accuracy: 0.9392\n",
      "Epoch 23/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0333 - accuracy: 0.9902 - val_loss: 0.1984 - val_accuracy: 0.9439\n",
      "Epoch 24/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 0.0336 - accuracy: 0.9894 - val_loss: 0.2388 - val_accuracy: 0.9302\n",
      "Epoch 25/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 0.2667 - val_accuracy: 0.9234\n",
      "Epoch 26/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 0.2196 - val_accuracy: 0.9294\n",
      "Epoch 27/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 0.2560 - val_accuracy: 0.9315\n",
      "Epoch 28/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.2438 - val_accuracy: 0.9375\n",
      "Epoch 29/64\n",
      "73/73 [==============================] - 78s 1s/step - loss: 0.0379 - accuracy: 0.9882 - val_loss: 0.2720 - val_accuracy: 0.9315\n",
      "Epoch 30/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0374 - accuracy: 0.9870 - val_loss: 0.2264 - val_accuracy: 0.9405\n",
      "Epoch 31/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.2247 - val_accuracy: 0.9311\n",
      "Epoch 32/64\n",
      "73/73 [==============================] - 78s 1s/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.2084 - val_accuracy: 0.9418\n",
      "Epoch 33/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.2384 - val_accuracy: 0.9396\n",
      "Epoch 34/64\n",
      "73/73 [==============================] - 78s 1s/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.2237 - val_accuracy: 0.9409\n",
      "Epoch 35/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.2252 - val_accuracy: 0.9375\n",
      "Epoch 36/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.3061 - val_accuracy: 0.9281\n",
      "Epoch 37/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.2563 - val_accuracy: 0.9375\n",
      "Epoch 38/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.2235 - val_accuracy: 0.9478\n",
      "Epoch 39/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9499\n",
      "Epoch 40/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 8.8431e-04 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9486\n",
      "Epoch 41/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 7.0128e-04 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9512\n",
      "Epoch 42/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 6.0218e-04 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9499\n",
      "Epoch 43/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 5.2035e-04 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9529\n",
      "Epoch 44/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 4.6315e-04 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9503\n",
      "Epoch 45/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 4.1472e-04 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9508\n",
      "Epoch 46/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 3.7349e-04 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9495\n",
      "Epoch 47/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 3.3898e-04 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9503\n",
      "Epoch 48/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 3.1015e-04 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9491\n",
      "Epoch 49/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 2.8609e-04 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9495\n",
      "Epoch 50/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 2.6386e-04 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9495\n",
      "Epoch 51/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 2.4452e-04 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9499\n",
      "Epoch 52/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 2.2762e-04 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9499\n",
      "Epoch 53/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 2.1201e-04 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9495\n",
      "Epoch 54/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 1.9694e-04 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9503\n",
      "Epoch 55/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 1.8430e-04 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9495\n",
      "Epoch 56/64\n",
      "73/73 [==============================] - 78s 1s/step - loss: 1.7353e-04 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9491\n",
      "Epoch 57/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 1.6241e-04 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9491\n",
      "Epoch 58/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 1.5235e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9491\n",
      "Epoch 59/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 1.4381e-04 - accuracy: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.9499\n",
      "Epoch 60/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 1.3557e-04 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9508\n",
      "Epoch 61/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 1.2766e-04 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9503\n",
      "Epoch 62/64\n",
      "73/73 [==============================] - 76s 1s/step - loss: 1.2084e-04 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9508\n",
      "Epoch 63/64\n",
      "73/73 [==============================] - 77s 1s/step - loss: 1.1401e-04 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.9495\n",
      "Epoch 64/64\n",
      "73/73 [==============================] - 78s 1s/step - loss: 1.0761e-04 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9503\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_categorical, \n",
    "                    epochs=64, batch_size=128, validation_data=(X_test, y_test_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "42f24793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 11s 151ms/step\n",
      "Test Accuracy: 0.3022260273972603\n",
      "Confusion Matrix:\n",
      " [[138  10 333  88]\n",
      " [ 55  14 461  56]\n",
      " [ 79   8 469  64]\n",
      " [ 89  16 371  85]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test_categorical, axis=1)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "confusion_mat = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c509e339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation losses\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(1, 64 + 1)\n",
    "\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261df977",
   "metadata": {},
   "source": [
    "**c)** What is the number of **total** hidden layers in your architecture if you \"unravel\" your network through time. Note that the answer completely depends on your architecture. **(3 points)** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982335ed",
   "metadata": {},
   "source": [
    "The number of Hidden layers is 1, the hidden layer being Bi-Directional(LSTM) layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
