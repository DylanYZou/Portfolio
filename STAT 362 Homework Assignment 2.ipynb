{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "171ee477",
   "metadata": {},
   "source": [
    "# Homework Assignment 2 - Exploring Supervised Learning: Multi-Class, Large-Margin, Non-linear and Non-parametric\n",
    "### **Due:** Thursday, May 5, 11:59pm\n",
    "### Total: 100 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243af34",
   "metadata": {},
   "source": [
    "## Import all the libraries and tools you need below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef2a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir(\"C:\\Data\")\n",
    "os.getcwd()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from numpy import log,dot,e,shape\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.special import softmax\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "from numpy import log,dot,e,shape\n",
    "from numpy.linalg import norm\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import make_blobs, make_circles\n",
    "\n",
    "def pr_auc(y_true, probas_pred):\n",
    " # calculate precision-recall curve\n",
    " p, r, _ = precision_recall_curve(y_true, probas_pred)\n",
    " # calculate area under curve\n",
    " return auc(r, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c77038",
   "metadata": {},
   "source": [
    "\n",
    "## **1)** Multi-Class Logistic Regression (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c60a4",
   "metadata": {},
   "source": [
    "In this question, you will extend your custom Logistic Regression model so that it can handle multiclass classification tasks. You will use the One-vs-All approach for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172b3ee2",
   "metadata": {},
   "source": [
    "**a)** Upload the **phone_price.csv** file. Each instance in this dataset is a phone and the features are certain specifications. The **price_range** column is the price level of the phone, 0 being the cheapest and 3 being the most expensive. \n",
    "\n",
    "Split the features and the target column into different variables. Print how many instances there are for each class.\n",
    "\n",
    "**(2 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd517558",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('phone_price.csv')\n",
    "X = data.drop(columns = 'price_range')\n",
    "y = data['price_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195a66a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "battery_power    2477037.0\n",
       "blue                 990.0\n",
       "clock_speed         3044.5\n",
       "dual_sim            1019.0\n",
       "fc                  8619.0\n",
       "four_g              1043.0\n",
       "int_memory         64093.0\n",
       "m_dep               1003.5\n",
       "mobile_wt         280498.0\n",
       "n_cores             9041.0\n",
       "pc                 19833.0\n",
       "px_height        1290216.0\n",
       "px_width         2503031.0\n",
       "ram              4248426.0\n",
       "sc_h               24613.0\n",
       "sc_w               11534.0\n",
       "talk_time          22022.0\n",
       "three_g             1523.0\n",
       "touch_screen        1006.0\n",
       "wifi                1014.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dadfe3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "battery_power    2000\n",
       "blue             2000\n",
       "clock_speed      2000\n",
       "dual_sim         2000\n",
       "fc               2000\n",
       "four_g           2000\n",
       "int_memory       2000\n",
       "m_dep            2000\n",
       "mobile_wt        2000\n",
       "n_cores          2000\n",
       "pc               2000\n",
       "px_height        2000\n",
       "px_width         2000\n",
       "ram              2000\n",
       "sc_h             2000\n",
       "sc_w             2000\n",
       "talk_time        2000\n",
       "three_g          2000\n",
       "touch_screen     2000\n",
       "wifi             2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1a32fe",
   "metadata": {},
   "source": [
    "**b)** Split the data into training and test datasets with a **80-20** split. **Make sure you stratify with the target column.** Use **random_state=2**. Then, scale the features of both datasets.\n",
    "\n",
    "**(2 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ddfd001",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2, random_state = 2, stratify=data[['price_range']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7347df",
   "metadata": {},
   "source": [
    "**c)** Why is stratification important for this question even though the classes are balanced? **(2 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82ddc1",
   "metadata": {},
   "source": [
    "Because price range is not binary, like 0 and 1's but rather from a range of 0-3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8052f6",
   "metadata": {},
   "source": [
    "**d)** Copy your custom Logistic Regression code from the previous assignment. **(0 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c293f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(dimension):\n",
    "    \n",
    "    weights = np.random.rand(dimension,)\n",
    "    bias = np.random.rand()\n",
    "    return weights,bias\n",
    "\n",
    "def predict(model_parameters,x_test, threshold):\n",
    "    weights = model_parameters['weights']\n",
    "    bias = model_parameters['bias']\n",
    "    z = np.dot(X_test, weights) + bias\n",
    "    y_pred = sigmoid(z)\n",
    "    return (y_pred >= threshold).astype(int)\n",
    "\n",
    "def sigmoid(z):\n",
    "    y_output = 1/(1 + np.exp(-z))\n",
    "    #y_output = np.maximum(y_output, 0.9999) #upper bound\n",
    "    #y_output = np.minimum(y_output, 0.0001) #lower bound\n",
    "    return y_output\n",
    "\n",
    "def calculate_cost_gradient(weights,bias,x_train,y_train):\n",
    "    \n",
    "    z = np.dot(x_train,weights)\n",
    "    \n",
    "    # Calculate the cost\n",
    "    y_output = sigmoid(np.dot(x_train,weights) + bias)\n",
    "    cost = (-1/len(y_train)) * np.sum(np.dot(y_train, np.log(sigmoid(z)))\n",
    "            + np.dot((1-y_train),np.log(1-sigmoid(z))))\n",
    "    cost = np.sum(cost) / x_train.shape[0]\n",
    "    \n",
    "    # Gradients\n",
    "    derivative_weight = np.dot(x_train.T,(y_output-y_train))/x_train.shape[0]\n",
    "    derivative_bias = np.sum(y_output-y_train)/x_train.shape[0]\n",
    "    gradients = {\"Gradient Weight\" : derivative_weight, \"Gradient Bias\" : derivative_bias}\n",
    "    \n",
    "    return cost,gradients\n",
    "\n",
    "def GradientDescent(weights,bias,x_train,y_train,lr,iters,tol):\n",
    "    costList = []\n",
    "    index = []\n",
    "    cost_previous = 999999999999\n",
    "    \n",
    "    #for each iteration, update weight and bias values\n",
    "    for i in range(iters):\n",
    "        old_weights = weights\n",
    "        \n",
    "        #For the current weights and bias, calculate the cost and the gradients\n",
    "        cost,gradients = calculate_cost_gradient(weights,bias,x_train,y_train)\n",
    "        #Update the weights and the bias\n",
    "        weights = weights - lr * gradients[\"Gradient Weight\"]\n",
    "        bias = bias - lr * gradients[\"Gradient Bias\"]\n",
    "        \n",
    "        new_weights = weights\n",
    "        \n",
    "        #Add the current cost and the intex to the list\n",
    "        costList.append(cost)\n",
    "        index.append(i)\n",
    "        dif = cost_previous - cost\n",
    "        if np.sqrt(np.sum((old_weights - new_weights)**2)) < tol:\n",
    "            break\n",
    "    \n",
    "    if i == iters-1:\n",
    "        print('Warning: Algorithm not converged.')\n",
    "            \n",
    "    #Save the trained weights and bias to the parameters dict\n",
    "    model_parameters = {\"weights\": weights,\"bias\": bias}\n",
    "    \n",
    "    #Print the number of iterations and the cost\n",
    "    print(\"iteration:\",len(index))\n",
    "    print(\"cost:\",cost)\n",
    "\n",
    "    #Plot to see how the cost decreased\n",
    "    plt.plot(index,costList)\n",
    "    plt.xlabel(\"Number of Iterations\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    \n",
    "    #Return the final parameters\n",
    "    return model_parameters\n",
    "\n",
    "def logistic_regression(x_train,y_train,x_test,y_test,lr,iters, tol, threshold=0.5):\n",
    "\n",
    "    weights,bias = initialize(x_train.shape[1])\n",
    "    \n",
    "    parameters = GradientDescent(weights,bias,x_train,y_train,lr,iters, tol)\n",
    "\n",
    "    y_prediction = predict(parameters,x_test, threshold)\n",
    "    \n",
    "    print(\"Test Accuracy: {:.2f}%\".format((100 - np.mean(np.abs(y_prediction - y_test))*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d0880",
   "metadata": {},
   "source": [
    "**e)** Write a **logistic_regression_mc** function. It should take the exact same inputs as the custom logistic regression function above and return the parameters of all the models created as an array/dataframe. Call the function with the multi-class data. **(21 points)**\n",
    "\n",
    "- Loop through all the possible class values. **Do not hard code, use the inputs.** Be careful about the order.\n",
    "    - For each class value, create new train and test target columns.\n",
    "    - Call logistic_regression with the new target values and return the optimum parameters.\n",
    "    - Store the optimum parameters.\n",
    "    - Calculate the class probabilities for the test data using optimum parameters and store them in an array/dataframe.\n",
    "- Use argmax to return the class predictions.\n",
    "- Print the accuracy, multi-class confusion matrix and precision/recall values for each class. You can use sklearn functions for this step. (For an easy way to get precision and recall, check **classification_report**.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81796c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_mc(x_train, y_train, x_test, \n",
    "                           y_test, lr, iters, tol, threshold = 0.5):\n",
    "    \n",
    "    dimension = y_train.nunique()\n",
    "    dimension_ytrain = []\n",
    "    dimension_ytest = []\n",
    "    dimension_yprediction = []\n",
    "    dimension_optimal_parameter = []\n",
    "    dimension_weights = []\n",
    "    dimension_bias = []\n",
    "\n",
    "    for i in range(dimension):\n",
    "        dimension_ytrain.append([])\n",
    "        dimension_ytest.append([])\n",
    "        dimension_yprediction.append([])\n",
    "        dimension_optimal_parameter.append([])\n",
    "        dimension_weights.append([])\n",
    "        dimension_bias.append([])\n",
    "    \n",
    "    for i in range(dimension):\n",
    "        dimension_ytrain[i] = (y_train[0:] == i).astype(int)\n",
    "        dimension_ytest[i] = (y_test[0:] == i).astype(int)\n",
    "        \n",
    "        dimension_weights[i],dimension_bias[i] = initialize(x_train.shape[1])\n",
    "    \n",
    "        dimension_optimal_parameter[i] = GradientDescent(dimension_weights[i],\n",
    "                                                         dimension_bias[i],\n",
    "                                                         x_train,\n",
    "                                     dimension_ytrain[i],lr,iters,tol)\n",
    "        \n",
    "        \n",
    "        dimension_yprediction[i] = predict(dimension_optimal_parameter[i],x_test, threshold)\n",
    "        \n",
    "        print(\"Test Accuracy: {:.2f}%\".format((100 - np.mean(\n",
    "            np.abs(dimension_yprediction[i] - dimension_ytest[i]))*100)))\n",
    "        \n",
    "        print(np.argmax(dimension_yprediction[i]))\n",
    "        \n",
    "        #Multilabel confusion\n",
    "    #print(multilabel_confusion_matrix(dimension_ytrain[i],\n",
    "    #                                  dimension_yprediction[i],\n",
    "    #                                 sample_weight=dimension_weights))\n",
    "        #Precision Recall Curve\n",
    "    #print(classification_report(dimension_ytrain[i],\n",
    "    #                            dimension_yprediction[i],\n",
    "    #                           sample_weight=dimension_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eb88dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\AppData\\Local\\Temp/ipykernel_11876/3246653893.py:27: RuntimeWarning: divide by zero encountered in log\n",
      "  + np.dot((1-y_train),np.log(1-sigmoid(z))))\n",
      "C:\\Users\\dylan\\AppData\\Local\\Temp/ipykernel_11876/3246653893.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  y_output = 1/(1 + np.exp(-z))\n",
      "C:\\Users\\dylan\\AppData\\Local\\Temp/ipykernel_11876/3246653893.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = (-1/len(y_train)) * np.sum(np.dot(y_train, np.log(sigmoid(z)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Algorithm not converged.\n",
      "iteration: 100\n",
      "cost: nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 82.50%\n",
      "12\n",
      "Warning: Algorithm not converged.\n",
      "iteration: 100\n",
      "cost: nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 62.00%\n",
      "0\n",
      "Warning: Algorithm not converged.\n",
      "iteration: 100\n",
      "cost: nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 75.00%\n",
      "0\n",
      "Warning: Algorithm not converged.\n",
      "iteration: 100\n",
      "cost: nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 74.50%\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_mc(X_train, y_train, X_test, y_test,\n",
    "                      lr = 1, iters = 100, tol = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4248f1bf",
   "metadata": {},
   "source": [
    "**f)** Which classes are easier to predict? Which classes have more misclassifications? What does this tell you about the price ranges? (The last question is open-ended.) **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31da011",
   "metadata": {},
   "source": [
    "class 0 and class 3 are the easiest predictions, which means that the values that fall in between 0 and 3 have a harder time being classified correctly as 1 or 2. This seems to mean that 1 and 2 classes are relatively similar to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889aca4",
   "metadata": {},
   "source": [
    "## **2)** Linear Support Vector Machine (SVM) Classifier Margin (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c78088",
   "metadata": {},
   "source": [
    "In this question, you will explore the linear SVM classifier from sklearn some more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc1f054",
   "metadata": {},
   "source": [
    "**a)** Use the **creditcard.csv** as you did in your **Apr18** in-class assignment. The task is to classify normal vs. fraudulent transactions and you need to 5-fold cross-validate a SVC model to find the best C and the best CV score. This far, you have already coded in your in-class assignment. For this assignment, you need to *find* some more information about the model for each C value:\n",
    "\n",
    "- The number of support vectors for each C value. Note that the sklearn implementation calls any instance that is either on the margin or violates the margin a support vector.\n",
    "- The percentage of misclassified instances among those that violate the margin. (Think about this one.)\n",
    "\n",
    "**Note:**\n",
    "- In order to add all this, you need to directly train a model, which has not been the case because the cross_val_score did that for you. You should keep cross_val_score to keep the CV results, but train one model on the entire training data separately as well to return the above information.\n",
    "- Checking the SVC documentation will help with how to return the number of support vectors.\n",
    "- No need to use the test data yet, as the main goal is inference.\n",
    "\n",
    "**(10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2272fc51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6e4382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class0 = data[data['Class'] == 0]\n",
    "\n",
    "class1 = data[data['Class'] == 1]\n",
    "\n",
    "class0_small = class0.sample(n=1000, random_state=2)\n",
    "\n",
    "data_small = pd.concat([class0_small, class1])\n",
    "\n",
    "y = data_small['Class']\n",
    "X = data_small.drop(['Time', 'Amount', 'Class'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    random_state=0, \n",
    "                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56b3fc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0032362459546926\n",
      "1.0\n",
      "0.9578947368421052\n",
      "0.9130434782608695\n",
      "0.8387096774193549\n",
      "0.8032786885245902\n",
      "0.8571428571428571\n",
      "0.8727272727272727\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 14,  18,  22,  54,  58,  75,  99, 112, 206, 207, 219, 256, 293,\n",
      "       312, 343, 439], dtype=int64),)\n",
      "[array([309, 310]), array([184, 184]), array([95, 91]), array([69, 63]), array([62, 52]), array([61, 49]), array([56, 48]), array([55, 48])]\n"
     ]
    }
   ],
   "source": [
    "possible_hyperparam_vals = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "cv_scores = []\n",
    "support_vectors = []\n",
    "\n",
    "for val in possible_hyperparam_vals:\n",
    "    svm = SVC(C=val, kernel='linear',random_state = 1)\n",
    "    \n",
    "    scores = cross_val_score(svm, X_train, y_train, cv=5)\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    cv_scores.append(np.mean(scores)*100)\n",
    "    support_vectors.append(svm.n_support_)\n",
    "    print(svm.n_support_[1]/svm.n_support_[0])\n",
    "    \n",
    "plt.plot(possible_hyperparam_vals, np.array(cv_scores))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C value')\n",
    "plt.ylabel('Avg accuracy %')\n",
    "plt.show()\n",
    "\n",
    "y_test = np.asarray(y_test)\n",
    "misclassified = np.where(y_test != svm.predict(X_test))\n",
    "print(misclassified)\n",
    "print(support_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5c0fe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.571428571428571"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(misclassified[0])/len(svm.predict(X_test))*100\n",
    "#Around 3.57% is misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afcabd6",
   "metadata": {},
   "source": [
    "**b)** What do the results tell you about the distribution of the credit card transaction data and the limitations of a linear decision boundary? Keep in mind that:\n",
    "- As the margin gets tighter/larger, the decision boundary also changes.\n",
    "- There are support vectors that can be outside the margin but on the wrong side of it.\n",
    "\n",
    "**(5 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047fe73f",
   "metadata": {},
   "source": [
    "- SVM seems not suitable for large datasets as the linearity of the algorithm is undermined by the fact that the data set has more noise. If one wants to find a pattern outside a pattern that can easily be divided into by a linear pattern, then linear SVM seems not to be suitable for because support vectors can lie outside the margin but on the wrong side as the linearity can become strict as the margin becomes tighter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf0475",
   "metadata": {},
   "source": [
    "**c)** Using the best C value (picked with CV) and another 5-fold cross-validation, find the decision threshold that returns at least 95% recall and a precision as high as possible.\n",
    "- Note that **cross_val_predict** returns the class prediction probabilities for each instance when that instance was in the validation fold. It needs **method=\"predict_proba\"**.\n",
    "- You need to try all possible threshold values with a stepsize 0.01.\n",
    "- Unlike, cross_val_score, cross_val_predict is used before a for loop, not in it.\n",
    "- Initializing an empty dataframe and storing information there as the loop goes is highly suggested in order to easily return the threshold value you are looking for. \n",
    "\n",
    "**(15 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88c6fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "     # define evaluation procedure\n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "     # define the model evaluation the metric\n",
    "    metric = make_scorer(pr_auc, needs_proba=True)\n",
    "     # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dec0107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.75892857142857\n",
      "[[299  17]\n",
      " [  2 130]]\n",
      "0.8843537414965986\n",
      "0.9848484848484849\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=possible_hyperparam_vals[np.argmax(cv_scores)], \n",
    "          kernel='linear',random_state = 1, probability=True)\n",
    "\n",
    "#Train the classifier\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "#Predict the test labels\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "acc = svm.score(X_test, y_test)*100\n",
    "\n",
    "print(acc)\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(precision_score(y_pred, y_test))\n",
    "print(recall_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6463ad82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94744253, 0.05255747])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_score_cv = cross_val_predict(svm, X_train, y_train, \n",
    "                               method = \"predict_proba\")\n",
    "c_score_cv[possible_hyperparam_vals[np.argmax(cv_scores)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "494db99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#desicion threshold seems to be 0.05255747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83c424c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean PR AUC: nan (nan)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = evaluate_model(X_train, y_train, svm)\n",
    "# summarize performance\n",
    "print('Mean PR AUC: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2253adc6",
   "metadata": {},
   "source": [
    "## 3) Non-linear SVM (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8139ff",
   "metadata": {},
   "source": [
    "**a)** Upload the **magic_telescope.csv** file, which contains simulated measurements taken from [MAGIC telescope](https://en.wikipedia.org/wiki/MAGIC_(telescope)), used to detect gamma rays. Each instance in this dataset is a detection of an electromagnetic shower and the features are certain physical measurements. The last column shows whether the shower is caused by a gamma ray (g) or cosmic rays in the upper atmosphere - called a hadronic shower. (h)\n",
    "\n",
    "- While uploading the file, use **header=None** because the feature names are not given in the first row of the csv file.\n",
    "- Split the target (last) column and the features (everything else) into different variables. \n",
    "- Convert the target vector into 0s and 1s. \n",
    "- Split the data into training and test datasets with a **70-30 split**. Make sure you **stratify** with the target column. Use **random_state=2**. \n",
    "- Scale the features of both datasets.\n",
    "\n",
    "**(3 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a773f0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1       2       3       4         5        6        7   \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
       "\n",
       "        8         9  10  \n",
       "0  40.0920   81.8828  g  \n",
       "1   6.3609  205.2610  g  \n",
       "2  76.9600  256.7880  g  \n",
       "3  10.4490  116.7370  g  \n",
       "4   4.6480  356.4620  g  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('magic_telescope.csv', header = None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b872f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[10]\n",
    "X = data.drop(columns = [10])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                            random_state=2, test_size=0.3,\n",
    "                                            stratify=data[[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce07f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit(X_train)\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "#y_train_scaled = sc.transform(y_train)\n",
    "#y_test_scaled = sc.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d73fee",
   "metadata": {},
   "source": [
    "**b)** The best linear SVM classifier returns around 79% accuracy for this dataset. (Feel free to check it out!) In this question, you will find out how much a kernelized SVM improves this.\n",
    "\n",
    "Find the best (or close enough) kernel and its best (or close enough) hyperparameter value by a grid search. Note that C, the regularization hyperparameter, is still there.\n",
    "- For C, use the values from 0.01 to 10, with an order of magnitude stepsize.\n",
    "- For the degree of the polynomial kernel, use 2, 3, 4.\n",
    "- For the gamma of the RBF kernel, use the values from 0.001 to 1, with an order of magnitude stepsize.\n",
    "\n",
    "**Note:**\n",
    "- Do not forget to put the kernel type in the grid.\n",
    "- The hyperparameter grid would still work with everything above put together, even though RBF kernel does not take a degree, or the polynomial kernel a gamma.\n",
    "- One thing to be careful while cross-validating data with unbalanced classes is to stratify the class values to each fold. This cannot be implemented by simply inputting cv=5 to the grid search object. So, you need an object that further customizes your split into folds. Check **StratifiedKFold** object.\n",
    "- A kernelized SVM is already slow to train. With such a big grid, it will take ages to run. Feel free to use GridSearchCV if you have confidence in your machine and/or have GPU access (and want **10 bonus points**), but using **RandomizedSearchCV** is highly suggested. Use **random_state=15**. Pick the number of sampled hyperparameter combos (**n_iter**) as you wish, as long as the best estimator exceeds 85% CV accuracy. Finally, return the test accuracy for the final model.\n",
    "- Setting **verbose=2** will show you where the grid search is as the code runs.\n",
    "\n",
    "**(17 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e2a05d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "C = [0.01, 0.1, 1, 10]\n",
    "\n",
    "param_grid = {'weights': ['uniform', 'distance'], \n",
    "              'C':[0.01, 0.1, 1, 10]}\n",
    "\n",
    "svm = SVC(C=C[0], kernel='poly',degree=3,random_state = 1, \n",
    "          probability=True, verbose = 2)\n",
    "\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "randomCV = RandomizedSearchCV(svm, param_grid, \n",
    "                              random_state=15, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c079bb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cv', 'error_score', 'estimator__C', 'estimator__break_ties', 'estimator__cache_size', 'estimator__class_weight', 'estimator__coef0', 'estimator__decision_function_shape', 'estimator__degree', 'estimator__gamma', 'estimator__kernel', 'estimator__max_iter', 'estimator__probability', 'estimator__random_state', 'estimator__shrinking', 'estimator__tol', 'estimator__verbose', 'estimator', 'n_iter', 'n_jobs', 'param_distributions', 'pre_dispatch', 'random_state', 'refit', 'return_train_score', 'scoring', 'verbose'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomCV.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "742fa659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 8 is smaller than n_iter=25. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter weights for estimator SVC(C=0.01, kernel='poly', probability=True, random_state=1, verbose=2). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11876/4137519956.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandomCV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'estimator__kernel'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1631\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1633\u001b[1;33m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[0;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m             random_state=self.random_state))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    584\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                 raise ValueError('Invalid parameter %s for estimator %s. '\n\u001b[0m\u001b[0;32m    231\u001b[0m                                  \u001b[1;34m'Check the list of available parameters '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                                  \u001b[1;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter weights for estimator SVC(C=0.01, kernel='poly', probability=True, random_state=1, verbose=2). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "search = randomCV.fit(X_train_scaled, y_train)\n",
    "search.cv_results_['estimator__kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed041305",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=C[2], kernel='poly',random_state = 1, probability=True)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Train the classifier\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "param_grid = {'weights': ['uniform', 'distance'], 'n_neighbors':range(1, 50, 2)}\n",
    "\n",
    "#GBC = GradientBoostingClassifier()\n",
    "#parameters = {'learning_rate': [0.01,0.02,0.03],\n",
    "#                  'subsample'    : [0.9, 0.5, 0.2],\n",
    "#                  'n_estimators' : [100,500,1000],\n",
    "#                  'max_depth'    : [4,6,8]\n",
    "#                 }\n",
    "\n",
    "grid_GBC = GridSearchCV(estimator=svm, param_grid = param_grid, \n",
    "                        cv = 2, n_jobs=500)\n",
    "grid_GBC.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "acc = svm.score(X_test, y_test)*100\n",
    "\n",
    "print(acc)\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(precision_score(y_pred, y_test))\n",
    "print(recall_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c8f5b0",
   "metadata": {},
   "source": [
    "## 4) KNN with Custom Weights (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93653b9a",
   "metadata": {},
   "source": [
    "In this question, you will expand the grid of n_neighbors and weights you coded in your **Apr20** in-class assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d28c9f",
   "metadata": {},
   "source": [
    "The weights input only has two built-in options: **'uniform'**, which means all neighbors have the same weight on the prediction and **'distance'**, which means the weights of the neighbors are inversely proportional with their distance to the predicted instance.\n",
    "\n",
    "While some other languages, such as R, give you some more built-in options on the weights, Python/sklearn gives you the option to define the weights method yourself as a user-defined function. You can then use the name of your function as the weights input. You need to write two user-defined functions and add them to the grid.\n",
    "\n",
    "- Note that all functions must have one input and one output only. The input is an array, which has the distances, and the output is an array of the same length as the input, which has the weights.\n",
    "- Write a **dist_sq** function, which returns $weights = \\frac{1}{(distances)^2}$.\n",
    "- Write a **dist_g10** function, which returns $weights = \\frac{1}{10*\\sqrt(2\\pi)} * e^{-distances^2/(2*10^2)}$. Note that this is the Gaussian equation with zero mean and sigma = 10.\n",
    "\n",
    "Add the functions to the weights part of your grid and rerun the whole thing with the same dataset. Return the best hyperparameter set and the test RMSE of the model with those hyperparameters. Note that you need to use the function names directly, not as strings.\n",
    "\n",
    "**Final Note from Emre:** For the life of me, I could not figure out how to use a user-defined function with multiple inputs (such as sigma as the second input instead of defining a function with a fixed sigma) as an input to a KNN object. Anyone who figures this out (if it is possible at all) will get **40 bonus points**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b755de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter dist_g10 for estimator KNeighborsRegressor(). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11876/369654564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_root_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    584\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                 raise ValueError('Invalid parameter %s for estimator %s. '\n\u001b[0m\u001b[0;32m    231\u001b[0m                                  \u001b[1;34m'Check the list of available parameters '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                                  \u001b[1;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter dist_g10 for estimator KNeighborsRegressor(). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "\n",
    "param_grid = {'weights': ['uniform', 'distance'],\n",
    "              'dist_sq': [1/(np.square(np.pi))],\n",
    "              'dist_g10': [1/(10*(np.sqrt(2*(np.pi))))],\n",
    "              'n_neighbors':range(1, 50, 2)}\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='neg_root_mean_squared_error', return_train_score=False, verbose=1)\n",
    " \n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24d09bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter dist_g10 for estimator KNeighborsRegressor(). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11876/4067836050.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_root_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    584\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                 raise ValueError('Invalid parameter %s for estimator %s. '\n\u001b[0m\u001b[0;32m    231\u001b[0m                                  \u001b[1;34m'Check the list of available parameters '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                                  \u001b[1;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter dist_g10 for estimator KNeighborsRegressor(). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='neg_root_mean_squared_error', return_train_score=False, verbose=1)\n",
    " \n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "results = grid.cv_results_\n",
    "\n",
    "results_df = pd.DataFrame(results['params'])\n",
    "results_df['MAE'] = -results['mean_test_score']\n",
    "results_df2 = results_df.pivot(index='n_neighbors', columns='weights', values='MAE')\n",
    "sns.heatmap(results_df2)\n",
    "plt.plot()\n",
    "\n",
    "knn_final = KNeighborsRegressor(n_neighbors=grid.best_params_['n_neighbors'], weights=grid.best_params_['weights'])\n",
    "knn_final.fit(X_train_scaled, y_train)\n",
    "y_pred = knn_final.predict(X_test_scaled)\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfccebf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11876/1533987457.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mknn_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_neighbors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mknn_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "knn_final = KNeighborsRegressor(n_neighbors=grid.best_params_['n_neighbors'], weights=grid.best_params_['weights'])\n",
    "knn_final.fit(X_train_scaled, y_train)\n",
    "y_pred = knn_final.predict(X_test_scaled)\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "rf = RandomForestRegressor(max_depth=7, n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8064d",
   "metadata": {},
   "source": [
    "## 5) Final KNN Question (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269532db",
   "metadata": {},
   "source": [
    "While KNN is a powerful model and very easy to implement and understand, come up with two different reasons why it can create problems in real-life situations. (Think about how long the prediction stage takes and what is necessary to have for that prediction stage. You can also compare it to a parametric model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75579628",
   "metadata": {},
   "source": [
    "- The runtime of KNN can be very long, and thus take more resources than possible\n",
    "- https://www.mygreatlearning.com/blog/knn-algorithm-introduction/ according to this website, KNN is a lazy algorithm meaning it doesn't use any of the training data to make generalizations, which could be problematic for the reason that one might aim to make generalizations for data simplification reasons amongst other reasons."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
