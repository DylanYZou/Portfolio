{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2d08f12d",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction problems: Report\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe6ec7",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. This is the template you may use to submit your code and report for the prediction problems on Kaggle.\n",
    "\n",
    "2. You may modify the template if you deem fit, but it should have the information asked below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d691ac",
   "metadata": {},
   "source": [
    "## A.1) Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaaaea5",
   "metadata": {},
   "source": [
    "Mention the data cleaning steps taken to prepare your data for developing the model. This may include imputing missing values, dealing with outliers, combining levels of categorical variable(s), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94664bd",
   "metadata": {},
   "source": [
    "* Put your data cleaning/preparation code with comments here\n",
    "* The code should begin from reading the train data\n",
    "* The code should end when you obtain the data used to develop the model in A.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7078479c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Data'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"C:\\Data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e143c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrix\n",
    "from pyearth import Earth\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, roc_curve, auc, precision_recall_curve, make_scorer,\n",
    "                             recall_score, accuracy_score, precision_score, confusion_matrix)\n",
    "from sklearn.model_selection import (cross_val_score, train_test_split, KFold, StratifiedKFold,\n",
    "                                     GridSearchCV, ParameterGrid)\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.ensemble import (BaggingRegressor, BaggingClassifier, RandomForestRegressor, RandomForestClassifier, \n",
    "                              GradientBoostingRegressor, GradientBoostingClassifier, AdaBoostRegressor, AdaBoostClassifier, \n",
    "                              VotingRegressor, VotingClassifier, StackingRegressor, StackingClassifier)\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import itertools as it\n",
    "import xgboost as xgb\n",
    "import time as time\n",
    "import random\n",
    "from skimpy import clean_columns\n",
    "\n",
    "#Libraries for visualizing trees\n",
    "from sklearn.tree import export_graphviz \n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51430c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission.head()\n",
    "y_train = train['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e19ab73",
   "metadata": {},
   "source": [
    "Dropping Categorical, but not the Nulls just yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df6a3777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_clean(data):\n",
    "    data = data.replace([np.inf], np.nan)\n",
    "    data = data.replace([-np.inf], np.nan)\n",
    "    \n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    data = data.drop(categorical_columns, axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "train_cleaned = function_clean(train)\n",
    "test_cleaned = function_clean(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1608757",
   "metadata": {},
   "source": [
    "## A.2) Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761fff41",
   "metadata": {},
   "source": [
    "Mention any major insights you obtained from the data, which you used to develop the model. Please put your code or visualizations here if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da91208e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y       1.000000\n",
       "x146    0.378696\n",
       "x102    0.378436\n",
       "x014    0.364737\n",
       "x581    0.346549\n",
       "          ...   \n",
       "x465         NaN\n",
       "x518         NaN\n",
       "x594         NaN\n",
       "x643         NaN\n",
       "x703         NaN\n",
       "Name: y, Length: 756, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = train_cleaned.corr().sort_values(by = 'y', ascending = False)\n",
    "corr_matrix['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf90456",
   "metadata": {},
   "source": [
    "Whilst we still had our null values and the potential unrepresented data in there, I wanted to use KNN to predict the null values, but realized this would be difficult with the faint correlations of the correlation matrix.\n",
    "\n",
    "I realize I could've use something like a PCA in the aim of something like this, or grouping certain variables via desicion trees into a single variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdbfb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nulls(df):\n",
    "    \n",
    "    null_counts = df.isnull().sum()\n",
    "    columns_to_drop = null_counts[null_counts > 50].index\n",
    "    df_dropped = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    return df_dropped\n",
    "\n",
    "test_cleaner = drop_nulls(test_cleaned)\n",
    "train_cleaner = drop_nulls(train_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d4e3a",
   "metadata": {},
   "source": [
    "For the rest I just replaced with averages to finally get rid of all the nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "860cc37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_avg(data):\n",
    "    for column in data.columns:\n",
    "        avg = data[column].mean()\n",
    "        data[column].fillna(avg, inplace=True)\n",
    "    return data\n",
    "\n",
    "train_avg = replace_avg(train_cleaner)\n",
    "test_avg = replace_avg(test_cleaner)\n",
    "test_avg.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "47f85015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x249', 'x336', 'x573', 'x314', 'x719', 'x360', 'x267', 'x120', 'x238', 'x043', 'x071', 'x672', 'x153', 'x274', 'x143', 'x031', 'x048', 'x292', 'x178', 'x329', 'x165', 'x136', 'x351', 'x442', 'x544', 'x186', 'x679', 'x207', 'x632', 'x313', 'x762', 'x500', 'x588', 'x205', 'x141', 'x075', 'x012', 'x182', 'x760', 'x705', 'x084', 'x278', 'x065', 'x119', 'x678', 'x433', 'x052', 'x627', 'x051', 'x386', 'x683', 'x546', 'x395', 'x228', 'x660', 'x050', 'x009', 'x393'}\n",
      "{'y'}\n"
     ]
    }
   ],
   "source": [
    "overlap1 = set(test_avg.columns) - set(train_avg.columns)\n",
    "overlap2 = set(train_avg.columns) - set(test_avg.columns)\n",
    "\n",
    "print(overlap1)\n",
    "print(overlap2)\n",
    "\n",
    "true_test = test_avg.drop(columns = overlap1)\n",
    "true_train = train_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48572d",
   "metadata": {},
   "source": [
    "I made sure to apply my data cleaning/analysis functions on the test just in case I needed the dataset to look at. overall, there was 618 columns for the train and 628 for the test, which suggests that the ladder half in the test data might have a different structure than the first half, but overall (only 10 columns lost), seem to be pretty similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f3107ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x010</th>\n",
       "      <th>...</th>\n",
       "      <th>x754</th>\n",
       "      <th>x755</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x761</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>26900000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.5707</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>297281012</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.304810e+09</td>\n",
       "      <td>13914.43</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>1.652405e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11927742.92</td>\n",
       "      <td>1798051.0</td>\n",
       "      <td>169000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>3320000000000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>160.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>135000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>162.0</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>100474819</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.288000e+10</td>\n",
       "      <td>15937.45</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.146667e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6324375.16</td>\n",
       "      <td>1932094.0</td>\n",
       "      <td>37000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>817.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>348000000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5316</td>\n",
       "      <td>117.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>6000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>109546590</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>5375</td>\n",
       "      <td>3.948791e+09</td>\n",
       "      <td>24563.46</td>\n",
       "      <td>6.73</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>9.871977e+08</td>\n",
       "      <td>0.43</td>\n",
       "      <td>3303184.55</td>\n",
       "      <td>3154159.0</td>\n",
       "      <td>11900000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>685.0</td>\n",
       "      <td>15.10</td>\n",
       "      <td>1.3758</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>158603315</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7480</td>\n",
       "      <td>93.45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>5376</td>\n",
       "      <td>9.279017e+10</td>\n",
       "      <td>21572.94</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>3.093006e+09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2649164.57</td>\n",
       "      <td>2934417.0</td>\n",
       "      <td>7220000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>558.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>36089167</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>23.6890</td>\n",
       "      <td>76.05</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>5377</td>\n",
       "      <td>2.700359e+10</td>\n",
       "      <td>23061.73</td>\n",
       "      <td>6.36</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>3.857656e+09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1825306.07</td>\n",
       "      <td>2395841.0</td>\n",
       "      <td>3960000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>650.0</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>1786891</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0</td>\n",
       "      <td>4.3710</td>\n",
       "      <td>80.30</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>5378</td>\n",
       "      <td>4.351107e+10</td>\n",
       "      <td>5739.04</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>1.318517e+09</td>\n",
       "      <td>0.29</td>\n",
       "      <td>144103.12</td>\n",
       "      <td>715173.0</td>\n",
       "      <td>4150000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.51</td>\n",
       "      <td>0.2719</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>194000000000</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2</td>\n",
       "      <td>24.6594</td>\n",
       "      <td>7.95</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>5379</td>\n",
       "      <td>3.972951e+09</td>\n",
       "      <td>3368.55</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.324317e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>471263.24</td>\n",
       "      <td>419675.0</td>\n",
       "      <td>42100000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>141.0</td>\n",
       "      <td>6.29</td>\n",
       "      <td>0.4605</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5740000000000</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0195</td>\n",
       "      <td>19.07</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5380 rows × 618 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          x001      x002  x003     x004          x005  x006  \\\n",
       "0        0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31   \n",
       "1        1  3.304810e+09  13914.43  5.37  0.00015  1.652405e+09  0.00   \n",
       "2        2  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00   \n",
       "3        3  1.288000e+10  15937.45  5.86  0.00020  2.146667e+09  0.00   \n",
       "4        4  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21   \n",
       "...    ...           ...       ...   ...      ...           ...   ...   \n",
       "5375  5375  3.948791e+09  24563.46  6.73  0.00035  9.871977e+08  0.43   \n",
       "5376  5376  9.279017e+10  21572.94  6.96  0.00120  3.093006e+09  0.30   \n",
       "5377  5377  2.700359e+10  23061.73  6.36  0.00065  3.857656e+09  0.35   \n",
       "5378  5378  4.351107e+10   5739.04  7.80  0.00065  1.318517e+09  0.29   \n",
       "5379  5379  3.972951e+09   3368.55  6.15  0.00000  1.324317e+09  0.00   \n",
       "\n",
       "             x007       x008                x010  ...    x754   x755    x756  \\\n",
       "0       266117.20   934577.0      26900000000000  ...    92.0   3.37  1.5707   \n",
       "1     11927742.92  1798051.0  169000000000000000  ...  1026.0   2.40  0.1173   \n",
       "2       774385.01   375738.0     135000000000000  ...   162.0   6.67  0.4582   \n",
       "3      6324375.16  1932094.0   37000000000000000  ...   817.0   7.40  0.3816   \n",
       "4       169860.29   474253.0       6000000000000  ...    62.0   1.14  0.0100   \n",
       "...           ...        ...                 ...  ...     ...    ...     ...   \n",
       "5375   3303184.55  3154159.0   11900000000000000  ...   685.0  15.10  1.3758   \n",
       "5376   2649164.57  2934417.0    7220000000000000  ...   558.0   4.38  0.2230   \n",
       "5377   1825306.07  2395841.0    3960000000000000  ...   650.0   1.87  0.1300   \n",
       "5378    144103.12   715173.0       4150000000000  ...    56.0   7.51  0.2719   \n",
       "5379    471263.24   419675.0      42100000000000  ...   141.0   6.29  0.4605   \n",
       "\n",
       "        x757           x758  x759  x761     x763    x764   y  \n",
       "0     0.0007      297281012  0.13     5   8.5127   14.28   5  \n",
       "1     0.1136  3320000000000  0.08     0   1.5700  160.12   1  \n",
       "2     0.0029      100474819  0.39     2   9.6800   25.06  11  \n",
       "3     0.0000   348000000000  0.25     1   4.5316  117.76   1  \n",
       "4     0.0005      109546590  0.11     1  16.2717    5.81   5  \n",
       "...      ...            ...   ...   ...      ...     ...  ..  \n",
       "5375  0.0000      158603315  0.05     0   2.7480   93.45   4  \n",
       "5376  0.0003       36089167  0.01     4  23.6890   76.05   8  \n",
       "5377  0.0057        1786891  0.53     0   4.3710   80.30  21  \n",
       "5378  0.0001   194000000000  0.29     2  24.6594    7.95  13  \n",
       "5379  0.0000  5740000000000  0.51     0   2.0195   19.07  28  \n",
       "\n",
       "[5380 rows x 618 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null = train_avg.columns[train_avg.corr()['y'].isnull()]\n",
    "true_test = true_test.drop(columns = null)\n",
    "true_train = true_train.drop(columns = null)\n",
    "\n",
    "true_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ca15ff2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x010</th>\n",
       "      <th>...</th>\n",
       "      <th>x753</th>\n",
       "      <th>x754</th>\n",
       "      <th>x755</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x761</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5380</td>\n",
       "      <td>6.507826e+10</td>\n",
       "      <td>7882.15</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>1.712586e+09</td>\n",
       "      <td>0.39</td>\n",
       "      <td>583617.74</td>\n",
       "      <td>862986.0</td>\n",
       "      <td>147000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>131.17</td>\n",
       "      <td>202.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>90204869909</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5</td>\n",
       "      <td>30.1213</td>\n",
       "      <td>27.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5381</td>\n",
       "      <td>3.122741e+09</td>\n",
       "      <td>4682.13</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.040914e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>190000.65</td>\n",
       "      <td>688710.0</td>\n",
       "      <td>11300000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>110.80</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>37449565014</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>10.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5382</td>\n",
       "      <td>3.888719e+10</td>\n",
       "      <td>7495.57</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.00285</td>\n",
       "      <td>2.160400e+09</td>\n",
       "      <td>0.42</td>\n",
       "      <td>351570.67</td>\n",
       "      <td>841523.0</td>\n",
       "      <td>41400000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>127.10</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>10847937619</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1</td>\n",
       "      <td>7.8513</td>\n",
       "      <td>21.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5383</td>\n",
       "      <td>7.727427e+10</td>\n",
       "      <td>4003.76</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0.00165</td>\n",
       "      <td>5.519591e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>320216.05</td>\n",
       "      <td>466131.0</td>\n",
       "      <td>20800000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>158.21</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>37200096</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0511</td>\n",
       "      <td>18.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5384</td>\n",
       "      <td>4.184868e+09</td>\n",
       "      <td>34874.72</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>1.046217e+09</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3349978.53</td>\n",
       "      <td>3711028.0</td>\n",
       "      <td>21100000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>129.62</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>10.90</td>\n",
       "      <td>2.8737</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16400000000000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6512</td>\n",
       "      <td>149.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>9778</td>\n",
       "      <td>3.217682e+09</td>\n",
       "      <td>2214.42</td>\n",
       "      <td>5.27</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.608841e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>520766.78</td>\n",
       "      <td>172141.0</td>\n",
       "      <td>38700000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>129.00</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>31446931515</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6431</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>9779</td>\n",
       "      <td>3.042820e+10</td>\n",
       "      <td>14279.29</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.00135</td>\n",
       "      <td>1.901762e+09</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1634334.25</td>\n",
       "      <td>1420919.0</td>\n",
       "      <td>2330000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>122.70</td>\n",
       "      <td>474.0</td>\n",
       "      <td>4.13</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18200000000000</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2</td>\n",
       "      <td>12.3538</td>\n",
       "      <td>68.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>9780</td>\n",
       "      <td>8.556628e+09</td>\n",
       "      <td>7518.26</td>\n",
       "      <td>6.74</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>2.852209e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>559939.70</td>\n",
       "      <td>911940.0</td>\n",
       "      <td>122000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>130.75</td>\n",
       "      <td>209.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>551000000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5226</td>\n",
       "      <td>29.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>9781</td>\n",
       "      <td>7.384902e+10</td>\n",
       "      <td>2556.73</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>1.605414e+09</td>\n",
       "      <td>0.25</td>\n",
       "      <td>186175.29</td>\n",
       "      <td>236336.0</td>\n",
       "      <td>2960000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>121.10</td>\n",
       "      <td>71.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0.5227</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>20500000000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>6</td>\n",
       "      <td>32.7632</td>\n",
       "      <td>10.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>9782</td>\n",
       "      <td>1.245804e+10</td>\n",
       "      <td>1481.99</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.114510e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>148362.27</td>\n",
       "      <td>144983.0</td>\n",
       "      <td>1980000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>148.30</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5.21</td>\n",
       "      <td>1.2049</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>121000000000000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9617</td>\n",
       "      <td>12.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows × 617 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          x001      x002  x003     x004          x005  x006  \\\n",
       "0     5380  6.507826e+10   7882.15  6.82  0.00210  1.712586e+09  0.39   \n",
       "1     5381  3.122741e+09   4682.13  8.17  0.00010  1.040914e+09  0.00   \n",
       "2     5382  3.888719e+10   7495.57  7.15  0.00285  2.160400e+09  0.42   \n",
       "3     5383  7.727427e+10   4003.76  6.53  0.00165  5.519591e+09  0.00   \n",
       "4     5384  4.184868e+09  34874.72  6.39  0.00065  1.046217e+09  0.50   \n",
       "...    ...           ...       ...   ...      ...           ...   ...   \n",
       "4398  9778  3.217682e+09   2214.42  5.27  0.00010  1.608841e+09  0.00   \n",
       "4399  9779  3.042820e+10  14279.29  6.18  0.00135  1.901762e+09  0.33   \n",
       "4400  9780  8.556628e+09   7518.26  6.74  0.00005  2.852209e+09  0.00   \n",
       "4401  9781  7.384902e+10   2556.73  6.47  0.00140  1.605414e+09  0.25   \n",
       "4402  9782  1.245804e+10   1481.99  5.92  0.00000  3.114510e+09  0.00   \n",
       "\n",
       "            x007       x008               x010  ...    x753    x754   x755  \\\n",
       "0      583617.74   862986.0    147000000000000  ...  131.17   202.0   4.01   \n",
       "1      190000.65   688710.0     11300000000000  ...  110.80    62.0   2.94   \n",
       "2      351570.67   841523.0     41400000000000  ...  127.10   140.0   1.45   \n",
       "3      320216.05   466131.0     20800000000000  ...  158.21   119.0   2.90   \n",
       "4     3349978.53  3711028.0  21100000000000000  ...  129.62  1061.0  10.90   \n",
       "...          ...        ...                ...  ...     ...     ...    ...   \n",
       "4398   520766.78   172141.0     38700000000000  ...  129.00   135.0   2.30   \n",
       "4399  1634334.25  1420919.0   2330000000000000  ...  122.70   474.0   4.13   \n",
       "4400   559939.70   911940.0    122000000000000  ...  130.75   209.0   3.92   \n",
       "4401   186175.29   236336.0      2960000000000  ...  121.10    71.0   6.44   \n",
       "4402   148362.27   144983.0      1980000000000  ...  148.30    65.0   5.21   \n",
       "\n",
       "        x756    x757             x758  x759  x761     x763    x764  \n",
       "0     0.0380  0.0010      90204869909  0.26     5  30.1213   27.95  \n",
       "1     0.1866  0.0192      37449565014  0.02     1   2.1282   10.18  \n",
       "2     0.0100  0.0017      10847937619  0.83     1   7.8513   21.27  \n",
       "3     0.4636  0.0000         37200096  0.51     4   9.0511   18.38  \n",
       "4     2.8737  0.0001   16400000000000  0.12     1   2.6512  149.68  \n",
       "...      ...     ...              ...   ...   ...      ...     ...  \n",
       "4398  0.0771  0.0095      31446931515  0.74     0   1.6431   22.42  \n",
       "4399  0.2828  0.0000   18200000000000  0.42     2  12.3538   68.09  \n",
       "4400  0.2890  0.0010     551000000000  0.67     1   2.5226   29.27  \n",
       "4401  0.5227  0.0127   20500000000000  0.67     6  32.7632   10.22  \n",
       "4402  1.2049  0.0000  121000000000000  0.40     0   1.9617   12.18  \n",
       "\n",
       "[4403 rows x 617 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b2555130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            VIF\n",
      "id    10.903311\n",
      "x402   8.413305\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = true_train.corr()\n",
    "\n",
    "vif = pd.DataFrame(index=true_train.columns, columns=['VIF'])\n",
    "\n",
    "for var in true_train.columns:\n",
    "    mask = true_train.columns != var\n",
    "    r_squared = 1.0 - corr_matrix.loc[var, mask].pow(2).sum()\n",
    "    vif.loc[var, 'VIF'] = 1.0 / (1.0 - r_squared)\n",
    "    \n",
    "high_vif_variables = vif[vif['VIF'] > 3]\n",
    "print(high_vif_variables)\n",
    "\n",
    "#null = train_avg.columns[train_avg.corr()['y'].isnull()]\n",
    "#true_test = true_test.drop(columns = null)\n",
    "#true_train = true_train.drop(columns = null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913f9d7a",
   "metadata": {},
   "source": [
    "Due to the severe lack of VIF variables, and the presumable high dimensionality of the data I was working with, I attempted to pivot towards developing a PCA in order to reduce the dimensionality and the variables drastically.\n",
    "\n",
    "I chose PCA because it is unsupervised seeing as it did not consider Y, unlike some other selection processes which consider proximity, etc etc. I was also having a lot of trouble selecting variables at this point so I decided to just start over as I wasn't sure if I was just cleaning significant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "75629672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x102    5380\n",
       "x570    5380\n",
       "x687    5380\n",
       "x651    5380\n",
       "x631    5380\n",
       "        ... \n",
       "x394       0\n",
       "x391       0\n",
       "x390       0\n",
       "x002       0\n",
       "y          0\n",
       "Length: 616, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_true = true_test.drop(columns = ['id', 'x402'])\n",
    "train_true = true_train.drop(columns = ['id','x402'])\n",
    "\n",
    "logtrain = np.log(train_true)\n",
    "logtest = np.log(test_true)\n",
    "\n",
    "logtrain = function_clean(logtrain)\n",
    "logtest = function_clean(logtest)\n",
    "\n",
    "#logtrain = replace_avg(logtrain)\n",
    "#logtest = replace_avg(logtest)\n",
    "\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled = scaler.transform(test_clean_true)\n",
    "logtrain.isnull().sum().sort_values(ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396f34c",
   "metadata": {},
   "source": [
    "I think I decided to log the data because some of the values seemed extreme; but also it had the other effect of giving infinite values which I had an excuse to now clean.\n",
    "\n",
    "I was also having some problems with dropna, so I just decided to make a function for myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8a8a5046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def drop_nulls(df):\n",
    "    \n",
    "    null_counts = df.isnull().sum()\n",
    "    columns_to_drop = null_counts[null_counts > 20].index\n",
    "    df_dropped = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    return df_dropped\n",
    "\n",
    "train_dropped = drop_nulls(logtrain)\n",
    "test_dropped = drop_nulls(logtest)\n",
    "\n",
    "train = replace_avg(train_dropped)\n",
    "test = replace_avg(test_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c652e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap1 = set(test.columns) - set(train.columns)\n",
    "overlap2 = set(train.columns) - set(test.columns)\n",
    "\n",
    "_test = test.drop(columns = overlap1)\n",
    "_train = train.drop(columns = overlap2)\n",
    "_ytrain = train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7c83b586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x005</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x010</th>\n",
       "      <th>x014</th>\n",
       "      <th>x015</th>\n",
       "      <th>x017</th>\n",
       "      <th>...</th>\n",
       "      <th>x736</th>\n",
       "      <th>x740</th>\n",
       "      <th>x741</th>\n",
       "      <th>x744</th>\n",
       "      <th>x747</th>\n",
       "      <th>x753</th>\n",
       "      <th>x754</th>\n",
       "      <th>x755</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.898856</td>\n",
       "      <td>8.972356</td>\n",
       "      <td>1.919859</td>\n",
       "      <td>21.261270</td>\n",
       "      <td>13.277001</td>\n",
       "      <td>13.668154</td>\n",
       "      <td>32.621454</td>\n",
       "      <td>1.574846</td>\n",
       "      <td>-0.171150</td>\n",
       "      <td>0.165514</td>\n",
       "      <td>...</td>\n",
       "      <td>12.851466</td>\n",
       "      <td>0.570980</td>\n",
       "      <td>-0.082616</td>\n",
       "      <td>6.134309</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>4.876494</td>\n",
       "      <td>5.308268</td>\n",
       "      <td>1.388791</td>\n",
       "      <td>25.225349</td>\n",
       "      <td>-1.347074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.861977</td>\n",
       "      <td>8.451508</td>\n",
       "      <td>2.100469</td>\n",
       "      <td>20.763365</td>\n",
       "      <td>12.154783</td>\n",
       "      <td>13.442576</td>\n",
       "      <td>30.055824</td>\n",
       "      <td>1.252763</td>\n",
       "      <td>-0.263662</td>\n",
       "      <td>0.292670</td>\n",
       "      <td>...</td>\n",
       "      <td>13.041023</td>\n",
       "      <td>0.688135</td>\n",
       "      <td>-0.074580</td>\n",
       "      <td>5.643289</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.707727</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>1.078410</td>\n",
       "      <td>24.346261</td>\n",
       "      <td>-3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.383931</td>\n",
       "      <td>8.922067</td>\n",
       "      <td>1.967112</td>\n",
       "      <td>21.493559</td>\n",
       "      <td>12.770166</td>\n",
       "      <td>13.642969</td>\n",
       "      <td>31.354302</td>\n",
       "      <td>1.075002</td>\n",
       "      <td>-0.147205</td>\n",
       "      <td>0.270027</td>\n",
       "      <td>...</td>\n",
       "      <td>12.507381</td>\n",
       "      <td>0.647103</td>\n",
       "      <td>-0.072091</td>\n",
       "      <td>5.700209</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>4.844974</td>\n",
       "      <td>4.941642</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>23.107241</td>\n",
       "      <td>-0.186330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.070627</td>\n",
       "      <td>8.294989</td>\n",
       "      <td>1.876407</td>\n",
       "      <td>22.431570</td>\n",
       "      <td>12.676751</td>\n",
       "      <td>13.052222</td>\n",
       "      <td>30.665974</td>\n",
       "      <td>0.985817</td>\n",
       "      <td>-0.322954</td>\n",
       "      <td>0.322083</td>\n",
       "      <td>...</td>\n",
       "      <td>10.547813</td>\n",
       "      <td>0.746688</td>\n",
       "      <td>-0.206585</td>\n",
       "      <td>6.139001</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>5.063923</td>\n",
       "      <td>4.779123</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>17.431822</td>\n",
       "      <td>-0.673345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.154741</td>\n",
       "      <td>10.459517</td>\n",
       "      <td>1.854734</td>\n",
       "      <td>20.768447</td>\n",
       "      <td>15.024464</td>\n",
       "      <td>15.126819</td>\n",
       "      <td>37.588049</td>\n",
       "      <td>1.909543</td>\n",
       "      <td>-0.342913</td>\n",
       "      <td>0.131028</td>\n",
       "      <td>...</td>\n",
       "      <td>14.617570</td>\n",
       "      <td>0.500775</td>\n",
       "      <td>-0.183322</td>\n",
       "      <td>6.327812</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>4.864607</td>\n",
       "      <td>6.966967</td>\n",
       "      <td>2.388763</td>\n",
       "      <td>30.428302</td>\n",
       "      <td>-2.120264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>21.891927</td>\n",
       "      <td>7.702746</td>\n",
       "      <td>1.662030</td>\n",
       "      <td>21.198780</td>\n",
       "      <td>13.163058</td>\n",
       "      <td>12.056069</td>\n",
       "      <td>31.286861</td>\n",
       "      <td>1.252763</td>\n",
       "      <td>-0.182602</td>\n",
       "      <td>0.104360</td>\n",
       "      <td>...</td>\n",
       "      <td>12.609993</td>\n",
       "      <td>0.451076</td>\n",
       "      <td>-0.062035</td>\n",
       "      <td>7.092565</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>4.905275</td>\n",
       "      <td>0.832909</td>\n",
       "      <td>24.171567</td>\n",
       "      <td>-0.301105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>24.138636</td>\n",
       "      <td>9.566566</td>\n",
       "      <td>1.821318</td>\n",
       "      <td>21.366047</td>\n",
       "      <td>14.306746</td>\n",
       "      <td>14.166814</td>\n",
       "      <td>35.384645</td>\n",
       "      <td>1.611436</td>\n",
       "      <td>-0.203846</td>\n",
       "      <td>0.157004</td>\n",
       "      <td>...</td>\n",
       "      <td>14.406182</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>-0.094579</td>\n",
       "      <td>6.500178</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>4.809742</td>\n",
       "      <td>6.161207</td>\n",
       "      <td>1.418277</td>\n",
       "      <td>30.532443</td>\n",
       "      <td>-0.867501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>22.869972</td>\n",
       "      <td>8.925090</td>\n",
       "      <td>1.908060</td>\n",
       "      <td>21.771360</td>\n",
       "      <td>13.235584</td>\n",
       "      <td>13.723329</td>\n",
       "      <td>32.435042</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>-0.134484</td>\n",
       "      <td>0.270027</td>\n",
       "      <td>...</td>\n",
       "      <td>13.276053</td>\n",
       "      <td>0.667829</td>\n",
       "      <td>-0.042073</td>\n",
       "      <td>6.096793</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.873287</td>\n",
       "      <td>5.342334</td>\n",
       "      <td>1.366092</td>\n",
       "      <td>27.035001</td>\n",
       "      <td>-0.400478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>25.025289</td>\n",
       "      <td>7.846484</td>\n",
       "      <td>1.867176</td>\n",
       "      <td>21.196647</td>\n",
       "      <td>12.134444</td>\n",
       "      <td>12.373010</td>\n",
       "      <td>28.716210</td>\n",
       "      <td>2.180417</td>\n",
       "      <td>-0.245612</td>\n",
       "      <td>0.173953</td>\n",
       "      <td>...</td>\n",
       "      <td>14.436462</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>-0.119192</td>\n",
       "      <td>6.114102</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>4.796617</td>\n",
       "      <td>4.262680</td>\n",
       "      <td>1.862529</td>\n",
       "      <td>30.651446</td>\n",
       "      <td>-0.400478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>23.245632</td>\n",
       "      <td>7.301141</td>\n",
       "      <td>1.778336</td>\n",
       "      <td>21.859338</td>\n",
       "      <td>11.907412</td>\n",
       "      <td>11.884372</td>\n",
       "      <td>28.314118</td>\n",
       "      <td>1.900614</td>\n",
       "      <td>-0.628259</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>...</td>\n",
       "      <td>15.591664</td>\n",
       "      <td>0.223144</td>\n",
       "      <td>-0.364491</td>\n",
       "      <td>6.408100</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>4.999237</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>1.650580</td>\n",
       "      <td>32.426812</td>\n",
       "      <td>-0.916291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x001       x002      x003       x005       x007       x008  \\\n",
       "0     24.898856   8.972356  1.919859  21.261270  13.277001  13.668154   \n",
       "1     21.861977   8.451508  2.100469  20.763365  12.154783  13.442576   \n",
       "2     24.383931   8.922067  1.967112  21.493559  12.770166  13.642969   \n",
       "3     25.070627   8.294989  1.876407  22.431570  12.676751  13.052222   \n",
       "4     22.154741  10.459517  1.854734  20.768447  15.024464  15.126819   \n",
       "...         ...        ...       ...        ...        ...        ...   \n",
       "4398  21.891927   7.702746  1.662030  21.198780  13.163058  12.056069   \n",
       "4399  24.138636   9.566566  1.821318  21.366047  14.306746  14.166814   \n",
       "4400  22.869972   8.925090  1.908060  21.771360  13.235584  13.723329   \n",
       "4401  25.025289   7.846484  1.867176  21.196647  12.134444  12.373010   \n",
       "4402  23.245632   7.301141  1.778336  21.859338  11.907412  11.884372   \n",
       "\n",
       "           x010      x014      x015      x017  ...       x736      x740  \\\n",
       "0     32.621454  1.574846 -0.171150  0.165514  ...  12.851466  0.570980   \n",
       "1     30.055824  1.252763 -0.263662  0.292670  ...  13.041023  0.688135   \n",
       "2     31.354302  1.075002 -0.147205  0.270027  ...  12.507381  0.647103   \n",
       "3     30.665974  0.985817 -0.322954  0.322083  ...  10.547813  0.746688   \n",
       "4     37.588049  1.909543 -0.342913  0.131028  ...  14.617570  0.500775   \n",
       "...         ...       ...       ...       ...  ...        ...       ...   \n",
       "4398  31.286861  1.252763 -0.182602  0.104360  ...  12.609993  0.451076   \n",
       "4399  35.384645  1.611436 -0.203846  0.157004  ...  14.406182  0.598837   \n",
       "4400  32.435042  1.386294 -0.134484  0.270027  ...  13.276053  0.667829   \n",
       "4401  28.716210  2.180417 -0.245612  0.173953  ...  14.436462  0.598837   \n",
       "4402  28.314118  1.900614 -0.628259  0.009950  ...  15.591664  0.223144   \n",
       "\n",
       "          x741      x744      x747      x753      x754      x755       x758  \\\n",
       "0    -0.082616  6.134309  3.637586  4.876494  5.308268  1.388791  25.225349   \n",
       "1    -0.074580  5.643289  1.098612  4.707727  4.127134  1.078410  24.346261   \n",
       "2    -0.072091  5.700209  2.890372  4.844974  4.941642  0.371564  23.107241   \n",
       "3    -0.206585  6.139001  2.639057  5.063923  4.779123  1.064711  17.431822   \n",
       "4    -0.183322  6.327812  1.386294  4.864607  6.966967  2.388763  30.428302   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "4398 -0.062035  7.092565  0.693147  4.859812  4.905275  0.832909  24.171567   \n",
       "4399 -0.094579  6.500178  2.772589  4.809742  6.161207  1.418277  30.532443   \n",
       "4400 -0.042073  6.096793  1.098612  4.873287  5.342334  1.366092  27.035001   \n",
       "4401 -0.119192  6.114102  3.828641  4.796617  4.262680  1.862529  30.651446   \n",
       "4402 -0.364491  6.408100  1.609438  4.999237  4.174387  1.650580  32.426812   \n",
       "\n",
       "          x759  \n",
       "0    -1.347074  \n",
       "1    -3.912023  \n",
       "2    -0.186330  \n",
       "3    -0.673345  \n",
       "4    -2.120264  \n",
       "...        ...  \n",
       "4398 -0.301105  \n",
       "4399 -0.867501  \n",
       "4400 -0.400478  \n",
       "4401 -0.400478  \n",
       "4402 -0.916291  \n",
       "\n",
       "[4403 rows x 302 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b6e5f9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x005</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x010</th>\n",
       "      <th>x014</th>\n",
       "      <th>x015</th>\n",
       "      <th>x017</th>\n",
       "      <th>...</th>\n",
       "      <th>x736</th>\n",
       "      <th>x740</th>\n",
       "      <th>x741</th>\n",
       "      <th>x744</th>\n",
       "      <th>x747</th>\n",
       "      <th>x753</th>\n",
       "      <th>x754</th>\n",
       "      <th>x755</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.296105</td>\n",
       "      <td>8.852400</td>\n",
       "      <td>2.048982</td>\n",
       "      <td>22.405733</td>\n",
       "      <td>12.491692</td>\n",
       "      <td>13.747849</td>\n",
       "      <td>30.923147</td>\n",
       "      <td>1.572774</td>\n",
       "      <td>-0.498156</td>\n",
       "      <td>0.270027</td>\n",
       "      <td>...</td>\n",
       "      <td>11.081788</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>-0.284159</td>\n",
       "      <td>5.594265</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>5.015158</td>\n",
       "      <td>4.521789</td>\n",
       "      <td>1.214913</td>\n",
       "      <td>19.510188</td>\n",
       "      <td>-2.040221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.918645</td>\n",
       "      <td>9.540682</td>\n",
       "      <td>1.680828</td>\n",
       "      <td>21.225498</td>\n",
       "      <td>16.294378</td>\n",
       "      <td>14.402214</td>\n",
       "      <td>39.668675</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>-0.168478</td>\n",
       "      <td>0.067659</td>\n",
       "      <td>...</td>\n",
       "      <td>15.112281</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>-0.041447</td>\n",
       "      <td>8.205732</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.857717</td>\n",
       "      <td>6.933423</td>\n",
       "      <td>0.875469</td>\n",
       "      <td>28.830986</td>\n",
       "      <td>-2.525729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.194904</td>\n",
       "      <td>8.292043</td>\n",
       "      <td>1.752672</td>\n",
       "      <td>21.629955</td>\n",
       "      <td>13.559824</td>\n",
       "      <td>12.836647</td>\n",
       "      <td>32.536296</td>\n",
       "      <td>1.890095</td>\n",
       "      <td>-0.205899</td>\n",
       "      <td>0.104360</td>\n",
       "      <td>...</td>\n",
       "      <td>11.110056</td>\n",
       "      <td>0.494696</td>\n",
       "      <td>-0.096164</td>\n",
       "      <td>6.883749</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>4.705558</td>\n",
       "      <td>5.087596</td>\n",
       "      <td>1.897620</td>\n",
       "      <td>18.425418</td>\n",
       "      <td>-0.941609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.278942</td>\n",
       "      <td>9.676427</td>\n",
       "      <td>1.768150</td>\n",
       "      <td>21.487182</td>\n",
       "      <td>15.659922</td>\n",
       "      <td>14.474115</td>\n",
       "      <td>38.149694</td>\n",
       "      <td>1.722767</td>\n",
       "      <td>-0.189105</td>\n",
       "      <td>0.223144</td>\n",
       "      <td>...</td>\n",
       "      <td>13.041788</td>\n",
       "      <td>0.593327</td>\n",
       "      <td>-0.060671</td>\n",
       "      <td>7.580465</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>4.848979</td>\n",
       "      <td>6.705639</td>\n",
       "      <td>2.001480</td>\n",
       "      <td>26.575468</td>\n",
       "      <td>-1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.145380</td>\n",
       "      <td>8.194506</td>\n",
       "      <td>2.017566</td>\n",
       "      <td>21.054338</td>\n",
       "      <td>12.042732</td>\n",
       "      <td>13.069496</td>\n",
       "      <td>29.422781</td>\n",
       "      <td>0.887891</td>\n",
       "      <td>-0.218636</td>\n",
       "      <td>0.039221</td>\n",
       "      <td>...</td>\n",
       "      <td>11.842922</td>\n",
       "      <td>0.357674</td>\n",
       "      <td>-0.096967</td>\n",
       "      <td>5.730295</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>4.871220</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>0.131028</td>\n",
       "      <td>18.511860</td>\n",
       "      <td>-2.207275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>22.096675</td>\n",
       "      <td>10.109015</td>\n",
       "      <td>1.906575</td>\n",
       "      <td>20.710381</td>\n",
       "      <td>15.010398</td>\n",
       "      <td>14.964232</td>\n",
       "      <td>37.015315</td>\n",
       "      <td>2.386926</td>\n",
       "      <td>-0.303337</td>\n",
       "      <td>0.246860</td>\n",
       "      <td>...</td>\n",
       "      <td>11.101172</td>\n",
       "      <td>0.620576</td>\n",
       "      <td>-0.147427</td>\n",
       "      <td>6.755431</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>4.848665</td>\n",
       "      <td>6.529419</td>\n",
       "      <td>2.714695</td>\n",
       "      <td>18.881917</td>\n",
       "      <td>-2.995732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>25.253606</td>\n",
       "      <td>9.979195</td>\n",
       "      <td>1.940179</td>\n",
       "      <td>21.852409</td>\n",
       "      <td>14.789755</td>\n",
       "      <td>14.892019</td>\n",
       "      <td>36.515631</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>-0.155680</td>\n",
       "      <td>0.246860</td>\n",
       "      <td>...</td>\n",
       "      <td>10.748050</td>\n",
       "      <td>0.620576</td>\n",
       "      <td>-0.085111</td>\n",
       "      <td>6.682334</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>4.844895</td>\n",
       "      <td>6.324359</td>\n",
       "      <td>1.477049</td>\n",
       "      <td>17.401503</td>\n",
       "      <td>-4.605170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>24.019236</td>\n",
       "      <td>10.045930</td>\n",
       "      <td>1.850028</td>\n",
       "      <td>22.073326</td>\n",
       "      <td>14.417258</td>\n",
       "      <td>14.689245</td>\n",
       "      <td>35.915020</td>\n",
       "      <td>1.521699</td>\n",
       "      <td>-0.260845</td>\n",
       "      <td>0.215111</td>\n",
       "      <td>...</td>\n",
       "      <td>10.224715</td>\n",
       "      <td>0.625938</td>\n",
       "      <td>-0.104679</td>\n",
       "      <td>6.116951</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>5.030830</td>\n",
       "      <td>6.476972</td>\n",
       "      <td>0.625938</td>\n",
       "      <td>14.395988</td>\n",
       "      <td>-0.634878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>24.496281</td>\n",
       "      <td>8.655047</td>\n",
       "      <td>2.054124</td>\n",
       "      <td>20.999774</td>\n",
       "      <td>11.878284</td>\n",
       "      <td>13.480280</td>\n",
       "      <td>29.054129</td>\n",
       "      <td>1.736951</td>\n",
       "      <td>-0.217610</td>\n",
       "      <td>0.239017</td>\n",
       "      <td>...</td>\n",
       "      <td>13.337651</td>\n",
       "      <td>0.678034</td>\n",
       "      <td>-0.119172</td>\n",
       "      <td>5.176319</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>4.792230</td>\n",
       "      <td>4.025352</td>\n",
       "      <td>2.016235</td>\n",
       "      <td>25.991124</td>\n",
       "      <td>-1.237874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>22.102775</td>\n",
       "      <td>8.122238</td>\n",
       "      <td>1.816452</td>\n",
       "      <td>21.004163</td>\n",
       "      <td>13.063172</td>\n",
       "      <td>12.947236</td>\n",
       "      <td>31.371069</td>\n",
       "      <td>1.981001</td>\n",
       "      <td>-0.293388</td>\n",
       "      <td>0.139762</td>\n",
       "      <td>...</td>\n",
       "      <td>14.760739</td>\n",
       "      <td>0.524729</td>\n",
       "      <td>-0.121829</td>\n",
       "      <td>6.611073</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.790820</td>\n",
       "      <td>4.948760</td>\n",
       "      <td>1.838961</td>\n",
       "      <td>29.378480</td>\n",
       "      <td>-0.673345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5380 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x001       x002      x003       x005       x007       x008  \\\n",
       "0     25.296105   8.852400  2.048982  22.405733  12.491692  13.747849   \n",
       "1     21.918645   9.540682  1.680828  21.225498  16.294378  14.402214   \n",
       "2     24.194904   8.292043  1.752672  21.629955  13.559824  12.836647   \n",
       "3     23.278942   9.676427  1.768150  21.487182  15.659922  14.474115   \n",
       "4     24.145380   8.194506  2.017566  21.054338  12.042732  13.069496   \n",
       "...         ...        ...       ...        ...        ...        ...   \n",
       "5375  22.096675  10.109015  1.906575  20.710381  15.010398  14.964232   \n",
       "5376  25.253606   9.979195  1.940179  21.852409  14.789755  14.892019   \n",
       "5377  24.019236  10.045930  1.850028  22.073326  14.417258  14.689245   \n",
       "5378  24.496281   8.655047  2.054124  20.999774  11.878284  13.480280   \n",
       "5379  22.102775   8.122238  1.816452  21.004163  13.063172  12.947236   \n",
       "\n",
       "           x010      x014      x015      x017  ...       x736      x740  \\\n",
       "0     30.923147  1.572774 -0.498156  0.270027  ...  11.081788  0.672944   \n",
       "1     39.668675  1.386294 -0.168478  0.067659  ...  15.112281  0.405465   \n",
       "2     32.536296  1.890095 -0.205899  0.104360  ...  11.110056  0.494696   \n",
       "3     38.149694  1.722767 -0.189105  0.223144  ...  13.041788  0.593327   \n",
       "4     29.422781  0.887891 -0.218636  0.039221  ...  11.842922  0.357674   \n",
       "...         ...       ...       ...       ...  ...        ...       ...   \n",
       "5375  37.015315  2.386926 -0.303337  0.246860  ...  11.101172  0.620576   \n",
       "5376  36.515631  1.686399 -0.155680  0.246860  ...  10.748050  0.620576   \n",
       "5377  35.915020  1.521699 -0.260845  0.215111  ...  10.224715  0.625938   \n",
       "5378  29.054129  1.736951 -0.217610  0.239017  ...  13.337651  0.678034   \n",
       "5379  31.371069  1.981001 -0.293388  0.139762  ...  14.760739  0.524729   \n",
       "\n",
       "          x741      x744      x747      x753      x754      x755       x758  \\\n",
       "0    -0.284159  5.594265  2.890372  5.015158  4.521789  1.214913  19.510188   \n",
       "1    -0.041447  8.205732  0.693147  4.857717  6.933423  0.875469  28.830986   \n",
       "2    -0.096164  6.883749  2.564949  4.705558  5.087596  1.897620  18.425418   \n",
       "3    -0.060671  7.580465  1.791759  4.848979  6.705639  2.001480  26.575468   \n",
       "4    -0.096967  5.730295  3.091042  4.871220  4.127134  0.131028  18.511860   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "5375 -0.147427  6.755431  1.386294  4.848665  6.529419  2.714695  18.881917   \n",
       "5376 -0.085111  6.682334  3.401197  4.844895  6.324359  1.477049  17.401503   \n",
       "5377 -0.104679  6.116951  1.945910  5.030830  6.476972  0.625938  14.395988   \n",
       "5378 -0.119172  5.176319  3.496508  4.792230  4.025352  2.016235  25.991124   \n",
       "5379 -0.121829  6.611073  1.098612  4.790820  4.948760  1.838961  29.378480   \n",
       "\n",
       "          x759  \n",
       "0    -2.040221  \n",
       "1    -2.525729  \n",
       "2    -0.941609  \n",
       "3    -1.386294  \n",
       "4    -2.207275  \n",
       "...        ...  \n",
       "5375 -2.995732  \n",
       "5376 -4.605170  \n",
       "5377 -0.634878  \n",
       "5378 -1.237874  \n",
       "5379 -0.673345  \n",
       "\n",
       "[5380 rows x 302 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76202c1c",
   "metadata": {},
   "source": [
    "I now have my training and test data, filtered down to only 357 columns but many more to go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d43d8af",
   "metadata": {},
   "source": [
    "## A.3) Feature selection/reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc78b0",
   "metadata": {},
   "source": [
    "Mention the steps for feature selection/reduction. Please put your code or visualizations here if needed.\n",
    "\n",
    "- I felt most comfortable with Neural Networks, so I used a PCA + Neural Ensemble Model to try and feature select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "dbcba7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import LSTM, MaxPooling1D, Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import Bidirectional, MaxPooling2D \n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "f46b0c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: [0.27962705 0.16901551 0.11529849 0.0724644  0.04958262 0.03393412\n",
      " 0.02692434 0.01961699 0.01933426 0.01330721 0.0127878  0.01053347\n",
      " 0.00877735 0.00833204 0.00771909 0.00660525 0.00635235 0.00591934\n",
      " 0.00539327 0.00498733 0.00489137 0.00459015 0.00435828 0.00419988\n",
      " 0.0040785  0.0040049  0.00357149 0.00339706 0.003222   0.00308328\n",
      " 0.00296318 0.00293465 0.00284362 0.00277817 0.0026599  0.00262823\n",
      " 0.00245465 0.0023865  0.0023454  0.00227897 0.00216725 0.00214226\n",
      " 0.00213617 0.00208896 0.00197638 0.00193201 0.00181369 0.00179038\n",
      " 0.00169091 0.00161075 0.00155345 0.00149478 0.00144642 0.00142061\n",
      " 0.00139727 0.00134688 0.00130079 0.00129026 0.0012299  0.00118318\n",
      " 0.00114639 0.00110025 0.00106091 0.00096858 0.00093972 0.00090459\n",
      " 0.00088482 0.00083055 0.00080745 0.00077907 0.00070803 0.00067277\n",
      " 0.00066672 0.00064352 0.00061853 0.00060275 0.00057887 0.00056499\n",
      " 0.00051498]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(_train)\n",
    "X_test_scaled = scaler.transform(_test)\n",
    "\n",
    "pca = PCA(n_components=.99)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "39495f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 79)"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "447e8d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4403, 79)"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a671c",
   "metadata": {},
   "source": [
    "Ending up with 79 variables to explain 99% of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd58e2ad",
   "metadata": {},
   "source": [
    "## A.4) Developing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e72c68",
   "metadata": {},
   "source": [
    "Mention the logical sequence of steps taken to obtain the final model. \n",
    "\n",
    "- Neural Network Attempt no. 1\n",
    "- Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5dd2cf",
   "metadata": {},
   "source": [
    "My first concern here was the feature selection. I was using neural networks to\n",
    "\n",
    "One of my first suggestions that came was to the model was to select the top couple of variables with respect to the correlation, but "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895b25b",
   "metadata": {},
   "source": [
    "# Single Neural Network Model using PCA data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb6aa1b",
   "metadata": {},
   "source": [
    "I got suspicions that the linear activation was performing suspiciously well, but I just kept trying neural network models to see if it could perform ok. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "effcde0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4403,)\n",
      "(4403, 79)\n",
      "(977,)\n",
      "(977, 79)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_pca, _ytrain, \n",
    "                                                    test_size=0.81829, random_state=36)\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "800b2074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_test_pca.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='MeanSquaredError', metrics=['RootMeanSquaredError'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "ccd055e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 1.0961 - root_mean_squared_error: 1.0469\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 0.5929 - root_mean_squared_error: 0.7700\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 3s 17ms/step - loss: 0.5180 - root_mean_squared_error: 0.7197\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 3s 17ms/step - loss: 0.4680 - root_mean_squared_error: 0.6841\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 0.4272 - root_mean_squared_error: 0.6536\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 0.3903 - root_mean_squared_error: 0.6248\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 3s 20ms/step - loss: 0.3513 - root_mean_squared_error: 0.5927\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 3s 20ms/step - loss: 0.3236 - root_mean_squared_error: 0.5689\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 4s 21ms/step - loss: 0.2924 - root_mean_squared_error: 0.5408\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 3s 20ms/step - loss: 0.2771 - root_mean_squared_error: 0.5264\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pca, _ytrain, \n",
    "                    epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "a02c8412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step\n",
      "Root Mean Squared Error on Validation Set: 1.2761605820333004\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error on Validation Set:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "e60fe409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5380</td>\n",
       "      <td>2.074097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5381</td>\n",
       "      <td>2.059591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5382</td>\n",
       "      <td>1.228719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5383</td>\n",
       "      <td>0.953873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5384</td>\n",
       "      <td>0.652356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>9778</td>\n",
       "      <td>1.354312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>9779</td>\n",
       "      <td>1.727634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>9780</td>\n",
       "      <td>2.806687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>9781</td>\n",
       "      <td>1.601340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>9782</td>\n",
       "      <td>1.477026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         0\n",
       "0     5380  2.074097\n",
       "1     5381  2.059591\n",
       "2     5382  1.228719\n",
       "3     5383  0.953873\n",
       "4     5384  0.652356\n",
       "...    ...       ...\n",
       "4398  9778  1.354312\n",
       "4399  9779  1.727634\n",
       "4400  9780  2.806687\n",
       "4401  9781  1.601340\n",
       "4402  9782  1.477026\n",
       "\n",
       "[4403 rows x 2 columns]"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)\n",
    "to_merge = pd.DataFrame(y_pred)\n",
    "merge = pd.concat([true_test['id'], to_merge], axis = 1)\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "5638f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.columns =['id', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "f610a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge['y'] = merge['y'].apply(lambda x: np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "2f3680bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5380</td>\n",
       "      <td>7.957357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5381</td>\n",
       "      <td>7.842758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5382</td>\n",
       "      <td>3.416849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5383</td>\n",
       "      <td>2.595744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5384</td>\n",
       "      <td>1.920058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>9778</td>\n",
       "      <td>3.874095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>9779</td>\n",
       "      <td>5.627323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>9780</td>\n",
       "      <td>16.554986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>9781</td>\n",
       "      <td>4.959676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>9782</td>\n",
       "      <td>4.379902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          y\n",
       "0     5380   7.957357\n",
       "1     5381   7.842758\n",
       "2     5382   3.416849\n",
       "3     5383   2.595744\n",
       "4     5384   1.920058\n",
       "...    ...        ...\n",
       "4398  9778   3.874095\n",
       "4399  9779   5.627323\n",
       "4400  9780  16.554986\n",
       "4401  9781   4.959676\n",
       "4402  9782   4.379902\n",
       "\n",
       "[4403 rows x 2 columns]"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = merge\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "0addad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.to_csv('y_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e02b0f",
   "metadata": {},
   "source": [
    "Ensemble Model using KNN feature select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e5f78ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "y_train = train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e4be191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = 'y')\n",
    "y = train['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c964a8",
   "metadata": {},
   "source": [
    "I just used the np.random functions to estimate the potential values of the empty values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b55fab68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>...</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5380</td>\n",
       "      <td>6.507826e+10</td>\n",
       "      <td>7882.15</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>1.712586e+09</td>\n",
       "      <td>0.39</td>\n",
       "      <td>583617.74</td>\n",
       "      <td>862986.0</td>\n",
       "      <td>63872.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>90204869909</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.1213</td>\n",
       "      <td>27.95</td>\n",
       "      <td>-0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5381</td>\n",
       "      <td>3.122741e+09</td>\n",
       "      <td>4682.13</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.040914e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>190000.65</td>\n",
       "      <td>688710.0</td>\n",
       "      <td>35407.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>37449565014</td>\n",
       "      <td>0.02</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>10.18</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5382</td>\n",
       "      <td>3.888719e+10</td>\n",
       "      <td>7495.57</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.00285</td>\n",
       "      <td>2.160400e+09</td>\n",
       "      <td>0.42</td>\n",
       "      <td>351570.67</td>\n",
       "      <td>841523.0</td>\n",
       "      <td>170240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>10847937619</td>\n",
       "      <td>0.83</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.8513</td>\n",
       "      <td>21.27</td>\n",
       "      <td>19.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5383</td>\n",
       "      <td>7.727427e+10</td>\n",
       "      <td>4003.76</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0.00165</td>\n",
       "      <td>5.519591e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>320216.05</td>\n",
       "      <td>466131.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>37200096</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0511</td>\n",
       "      <td>18.38</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5384</td>\n",
       "      <td>4.184868e+09</td>\n",
       "      <td>34874.72</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>1.046217e+09</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3349978.53</td>\n",
       "      <td>3711028.0</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8737</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16400000000000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.6512</td>\n",
       "      <td>149.68</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>9778</td>\n",
       "      <td>3.217682e+09</td>\n",
       "      <td>2214.42</td>\n",
       "      <td>5.27</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.608841e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>520766.78</td>\n",
       "      <td>172141.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>31446931515</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6431</td>\n",
       "      <td>22.42</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>9779</td>\n",
       "      <td>3.042820e+10</td>\n",
       "      <td>14279.29</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.00135</td>\n",
       "      <td>1.901762e+09</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1634334.25</td>\n",
       "      <td>1420919.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18200000000000</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.3538</td>\n",
       "      <td>68.09</td>\n",
       "      <td>-0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>9780</td>\n",
       "      <td>8.556628e+09</td>\n",
       "      <td>7518.26</td>\n",
       "      <td>6.74</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>2.852209e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>559939.70</td>\n",
       "      <td>911940.0</td>\n",
       "      <td>105542.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>551000000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.5226</td>\n",
       "      <td>29.27</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>9781</td>\n",
       "      <td>7.384902e+10</td>\n",
       "      <td>2556.73</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>1.605414e+09</td>\n",
       "      <td>0.25</td>\n",
       "      <td>186175.29</td>\n",
       "      <td>236336.0</td>\n",
       "      <td>655488.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5227</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>20500000000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>142.0</td>\n",
       "      <td>6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>32.7632</td>\n",
       "      <td>10.22</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>9782</td>\n",
       "      <td>1.245804e+10</td>\n",
       "      <td>1481.99</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.114510e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>148362.27</td>\n",
       "      <td>144983.0</td>\n",
       "      <td>4736.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2049</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>121000000000000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9617</td>\n",
       "      <td>12.18</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          x001      x002  x003     x004          x005  x006  \\\n",
       "0     5380  6.507826e+10   7882.15  6.82  0.00210  1.712586e+09  0.39   \n",
       "1     5381  3.122741e+09   4682.13  8.17  0.00010  1.040914e+09  0.00   \n",
       "2     5382  3.888719e+10   7495.57  7.15  0.00285  2.160400e+09  0.42   \n",
       "3     5383  7.727427e+10   4003.76  6.53  0.00165  5.519591e+09  0.00   \n",
       "4     5384  4.184868e+09  34874.72  6.39  0.00065  1.046217e+09  0.50   \n",
       "...    ...           ...       ...   ...      ...           ...   ...   \n",
       "4398  9778  3.217682e+09   2214.42  5.27  0.00010  1.608841e+09  0.00   \n",
       "4399  9779  3.042820e+10  14279.29  6.18  0.00135  1.901762e+09  0.33   \n",
       "4400  9780  8.556628e+09   7518.26  6.74  0.00005  2.852209e+09  0.00   \n",
       "4401  9781  7.384902e+10   2556.73  6.47  0.00140  1.605414e+09  0.25   \n",
       "4402  9782  1.245804e+10   1481.99  5.92  0.00000  3.114510e+09  0.00   \n",
       "\n",
       "            x007       x008      x009  ...    x756    x757             x758  \\\n",
       "0      583617.74   862986.0   63872.0  ...  0.0380  0.0010      90204869909   \n",
       "1      190000.65   688710.0   35407.0  ...  0.1866  0.0192      37449565014   \n",
       "2      351570.67   841523.0  170240.0  ...  0.0100  0.0017      10847937619   \n",
       "3      320216.05   466131.0      35.0  ...  0.4636  0.0000         37200096   \n",
       "4     3349978.53  3711028.0    1757.0  ...  2.8737  0.0001   16400000000000   \n",
       "...          ...        ...       ...  ...     ...     ...              ...   \n",
       "4398   520766.78   172141.0    1307.0  ...  0.0771  0.0095      31446931515   \n",
       "4399  1634334.25  1420919.0     826.0  ...  0.2828  0.0000   18200000000000   \n",
       "4400   559939.70   911940.0  105542.0  ...  0.2890  0.0010     551000000000   \n",
       "4401   186175.29   236336.0  655488.0  ...  0.5227  0.0127   20500000000000   \n",
       "4402   148362.27   144983.0    4736.0  ...  1.2049  0.0000  121000000000000   \n",
       "\n",
       "      x759   x760  x761  x762     x763    x764   x765  \n",
       "0     0.26    8.0     5   5.0  30.1213   27.95  -0.49  \n",
       "1     0.02   16.0     1   8.0   2.1282   10.18   0.55  \n",
       "2     0.83   35.0     1  19.0   7.8513   21.27  19.09  \n",
       "3     0.51    1.0     4   0.0   9.0511   18.38   4.11  \n",
       "4     0.12    2.0     1   2.0   2.6512  149.68   0.02  \n",
       "...    ...    ...   ...   ...      ...     ...    ...  \n",
       "4398  0.74    0.0     0   0.0   1.6431   22.42   1.67  \n",
       "4399  0.42    0.0     2   0.0  12.3538   68.09  -0.43  \n",
       "4400  0.67   25.0     1   9.0   2.5226   29.27   0.32  \n",
       "4401  0.67  142.0     6  56.0  32.7632   10.22  -0.75  \n",
       "4402  0.40    0.0     0   0.0   1.9617   12.18   2.84  \n",
       "\n",
       "[4403 rows x 766 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "\n",
    "def random_imputation(dataset):\n",
    "    # Create a boolean mask for missing values\n",
    "    missing_mask = dataset.isnull()\n",
    "\n",
    "    # Iterate over each column\n",
    "    for column in dataset.columns:\n",
    "        # Get the potential values from within the column\n",
    "        potential_values = dataset.loc[~missing_mask[column], column]\n",
    "\n",
    "        # Randomly select values to fill the missing values\n",
    "        random_fill = np.random.choice(potential_values, size=missing_mask[column].sum())\n",
    "\n",
    "        # Update the missing values in the column\n",
    "        dataset.loc[missing_mask[column], column] = random_fill\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "X_train = random_imputation(X)\n",
    "X_train\n",
    "\n",
    "X_test = random_imputation(test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d3b0ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_id = X_train['id']\n",
    "X_train = X_train.drop(columns = 'id')\n",
    "\n",
    "X_test_id = X_test['id']\n",
    "X_test = X_test.drop(columns = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a48b580d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['x001', 'x002', 'x003', 'x004', 'x005', 'x006', 'x007', 'x034', 'x037', 'x036', 'x035', 'x030', 'x033', 'x032', 'x031', 'x039', 'x038', 'x042', 'x040', 'x041', 'x028', 'x043', 'x044', 'x045', 'x046', 'x047', 'x048', 'x029', 'x025', 'x027', 'x016', 'x008', 'x009', 'x010', 'x011', 'x012', 'x013', 'x014', 'x015', 'x017', 'x026', 'x018', 'x019', 'x020', 'x021', 'x022', 'x023', 'x024', 'x099', 'x049', 'x100', 'x051', 'x076', 'x078', 'x079', 'x080', 'x081', 'x082', 'x083', 'x084', 'x085', 'x086', 'x087', 'x088', 'x089', 'x090', 'x091', 'x092', 'x093', 'x094', 'x095', 'x096', 'x097', 'x098', 'x077', 'x075', 'x052', 'x074', 'x053', 'x054', 'x055', 'x056', 'x057', 'x058', 'x059', 'x060', 'x061', 'x062', 'x063', 'x064', 'x065', 'x066', 'x067', 'x068', 'x069', 'x070', 'x071', 'x072', 'x073', 'x050']\n",
      "Total Explained Variance Ratio: 0.9999999999999991\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def select_PCA(X_train, X_test, n_components):\n",
    "\n",
    "    X_train_array = X_train.values\n",
    "    X_test_array = X_test.values\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    sorted_indices = np.argsort(explained_variance_ratio)[::-1]\n",
    "    selected_features = X_train.columns[sorted_indices[:n_components]].tolist()\n",
    "    total_explained_variance_ratio = np.sum(explained_variance_ratio)\n",
    "    \n",
    "    return X_train_pca, selected_features, X_test_pca, total_explained_variance_ratio\n",
    "\n",
    "X_train_pca, selected_features, X_test_pca, total_explained_variance = select_PCA(X_train, X_test, 100)\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Total Explained Variance Ratio:\", total_explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3116806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature indices: [  3  13  14  17  27  47  52  62  74  85  96 102 105 108 111 114 116 118\n",
      " 135 146 161 163 165 168 172 174 178 185 186 192 239 249 250 253 265 270\n",
      " 274 288 303 337 353 355 364 366 378 400 425 427 430 447 454 475 477 481\n",
      " 484 488 506 543 561 568 569 572 581 585 591 602 609 619 622 638 640 646\n",
      " 651 652 654 661 662 664 669 670 683 684 685 687 696 702 710 716 718 724\n",
      " 728 731 734 735 740 742 745 749 755 756]\n",
      "Selected feature names: Index(['x003', 'x013', 'x014', 'x017', 'x027', 'x047', 'x052', 'x062', 'x074',\n",
      "       'x085', 'x096', 'x102', 'x105', 'x108', 'x111', 'x114', 'x116', 'x118',\n",
      "       'x135', 'x146', 'x161', 'x163', 'x165', 'x168', 'x172', 'x174', 'x178',\n",
      "       'x185', 'x186', 'x192', 'x239', 'x249', 'x250', 'x253', 'x265', 'x270',\n",
      "       'x274', 'x288', 'x303', 'x337', 'x353', 'x355', 'x364', 'x366', 'x378',\n",
      "       'x400', 'x425', 'x427', 'x430', 'x447', 'x454', 'x475', 'x477', 'x481',\n",
      "       'x484', 'x488', 'x506', 'x543', 'x561', 'x568', 'x569', 'x572', 'x581',\n",
      "       'x585', 'x591', 'x602', 'x609', 'x619', 'x622', 'x638', 'x640', 'x646',\n",
      "       'x651', 'x652', 'x654', 'x661', 'x662', 'x664', 'x669', 'x670', 'x683',\n",
      "       'x684', 'x685', 'x687', 'x696', 'x702', 'x710', 'x716', 'x718', 'x724',\n",
      "       'x728', 'x731', 'x734', 'x735', 'x740', 'x742', 'x745', 'x749', 'x755',\n",
      "       'x756'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:302: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "C:\\Users\\dylan\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:302: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "C:\\Users\\dylan\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:307: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k=100)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "print(\"Selected feature indices:\", selected_feature_indices)\n",
    "\n",
    "feature_scores = selector.scores_\n",
    "feature_names = X.columns\n",
    "scores_df = pd.DataFrame({'Feature': feature_names, 'Score': feature_scores})\n",
    "\n",
    "# Store the selected feature names\n",
    "selected_feature_names = feature_names[selected_feature_indices]\n",
    "\n",
    "print(\"Selected feature names:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6d97d456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert feature_names and selected_features to sets\n",
    "feature_names_set = set(selected_feature_names)\n",
    "selected_features_set = set(selected_features)\n",
    "\n",
    "# Find the common features\n",
    "common_features = feature_names_set.intersection(selected_features_set)\n",
    "\n",
    "# Convert the common_features set back to a list if needed\n",
    "common_features = list(common_features)\n",
    "\n",
    "# Print the common features\n",
    "len(common_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8509d298",
   "metadata": {},
   "source": [
    "Attempted to create then an ensemble model that combines both in order to be iterated over many times so cross-validation of the folds can happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525887bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def ensemble_feature_selection(X_train, y_train, n_iterations, variance_ratio_thresholds, n_components, n_folds=5):\n",
    "    best_features = None\n",
    "    best_rmse = np.inf\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Apply random imputation to handle missing values\n",
    "        X_train_imputed = random_imputation(X_train)\n",
    "\n",
    "        # Compute PCA and explained variance ratio\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X_train_pca = pca.fit_transform(X_train_imputed)\n",
    "\n",
    "        # Train a KNN regressor and perform cross-validation\n",
    "        knn = KNeighborsRegressor()\n",
    "        scores = cross_val_score(knn, X_train_pca, y_train, cv=n_folds, scoring='neg_mean_squared_error')\n",
    "        rmse = np.sqrt(-np.mean(scores))\n",
    "\n",
    "        # Update the best features and RMSE if improved\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_features = X_train.columns[:n_components]\n",
    "\n",
    "    return best_features, best_rmse\n",
    "\n",
    "# Assuming you have X_train and y_train datasets, and the desired number of iterations\n",
    "\n",
    "n_iterations = 10\n",
    "variance_ratio_thresholds = [0.8, 0.9, 0.95]\n",
    "n_components = 100  # Manually set the number of components\n",
    "\n",
    "best_features, best_rmse = ensemble_feature_selection(\n",
    "    X_train, y_train, n_iterations, variance_ratio_thresholds, n_components\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Features:\", best_features)\n",
    "print(\"Best RMSE:\", best_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148744c",
   "metadata": {},
   "source": [
    "## A.5) Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef6e03",
   "metadata": {},
   "source": [
    "Please provide details of the models/approaches you attempted but encountered challenges or unfavorable outcomes. If feasible, kindly explain the reasons behind their ineffectiveness or lack of success. Additionally, highlight the significant challenges or issues you encountered during the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b5675",
   "metadata": {},
   "source": [
    "I feel like I had a hard time with some feature selection models like KNN, random forest, and gradient boosting because they just took a long time with my data without great results. Once I thought about it theoritically, things like KNN made sense on why they didn't work, because the RMSE wasn't necessarily based opon the number of neighbors I had assigned. I could have used a technique like gridsearch to find the most optimal hyperparameters but I feel like having seen great results with Neural networks in my STAT 362 class, I could use that much more comfortably than other ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7b917",
   "metadata": {},
   "source": [
    "## A.6) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0af5e",
   "metadata": {},
   "source": [
    "* Do you feel that you gain valuable experience, skills, and/or knowledge? If yes, please explain what they were. If no, please explain.\n",
    "* What are things you liked/disliked about the project and/or work on the project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef17a01",
   "metadata": {},
   "source": [
    "I feel like I learned so many new important things about machine learning that I wouldn't have been able to express in any other way. I think learning with this dataset, with no strict linear or dimensional pattern has been very helpful to my understanding of data science and statistics in general. For example, I feel like data cleaning desicions were very hard to make, and a lot of the traditional data cleaning desicions I think we make on various kinds of datasets.\n",
    "\n",
    "I also feel like I was able to combine my knowledge from various classes from 303-3, 362, and other classes in a way that felt so real world for me, and in a way that made all the math and other statistical stuff I learned feel relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f42714",
   "metadata": {},
   "source": [
    "## Please make sure your github repo has all the code and  ensure that your code is capable of reproducing the outcomes you have submitted. It is important to avoid any form of academic misconduct or cheating by using your peer's submission file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
